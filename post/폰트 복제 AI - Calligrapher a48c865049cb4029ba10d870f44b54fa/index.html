<!DOCTYPE html><html lang="ko" data-astro-cid-ztig7rse> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>상세</title><link rel="icon" href="/pages/favicon.svg" type="image/svg+xml"><link rel="icon" href="/pages/favicon-32x32.png" sizes="32x32"><link rel="apple-touch-icon" href="/pages/apple-touch-icon.png" sizes="180x180"><style>:root{color-scheme:light dark}body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}.wrap[data-astro-cid-ztig7rse]{max-width:860px;margin:0 auto;padding:20px}.topbar[data-astro-cid-ztig7rse]{position:sticky;top:0;backdrop-filter:blur(6px);background:color-mix(in oklab,canvas,transparent 35%);border-bottom:1px solid color-mix(in oklab,canvastext,transparent 90%);z-index:10}.topbar[data-astro-cid-ztig7rse] .inner[data-astro-cid-ztig7rse]{display:flex;align-items:center;gap:8px;padding:10px 20px;max-width:860px;margin:0 auto}.btn[data-astro-cid-ztig7rse]{appearance:none;border:1px solid color-mix(in oklab,canvastext,transparent 85%);background:transparent;color:inherit;border-radius:10px;padding:8px 12px;cursor:pointer;font-size:14px}.btn[data-astro-cid-ztig7rse].primary{background:#111827;color:#fff;border-color:#111827}@media (prefers-color-scheme: dark){.btn[data-astro-cid-ztig7rse].primary{background:#e5e7eb;color:#111827;border-color:#e5e7eb}}.hero[data-astro-cid-ztig7rse]{margin:14px 0 8px;display:none}.hero[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{width:100%;height:auto;border-radius:12px;display:block;background:#f3f4f6}article[data-astro-cid-ztig7rse]{line-height:1.72;font-size:16px}article[data-astro-cid-ztig7rse] :is(h1,h2,h3)[data-astro-cid-ztig7rse]{line-height:1.25;margin:24px 0 10px}article[data-astro-cid-ztig7rse] h1[data-astro-cid-ztig7rse]{font-size:28px}article[data-astro-cid-ztig7rse] h2[data-astro-cid-ztig7rse]{font-size:22px}article[data-astro-cid-ztig7rse] h3[data-astro-cid-ztig7rse]{font-size:18px}article[data-astro-cid-ztig7rse] p[data-astro-cid-ztig7rse]{margin:10px 0}article[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{max-width:100%;height:auto;border-radius:8px;background:#f3f4f6}article[data-astro-cid-ztig7rse] pre[data-astro-cid-ztig7rse]{overflow:auto;padding:14px;border:1px solid color-mix(in oklab,canvastext,transparent 90%);border-radius:10px;background:color-mix(in oklab,canvastext,transparent 96%)}article[data-astro-cid-ztig7rse] code[data-astro-cid-ztig7rse]:not(pre code){background:color-mix(in oklab,canvastext,transparent 94%);padding:2px 6px;border-radius:6px}article[data-astro-cid-ztig7rse] blockquote[data-astro-cid-ztig7rse]{border-left:3px solid #9CA3AF;margin:8px 0;padding:4px 12px;color:#6b7280}.actions[data-astro-cid-ztig7rse]{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0 18px}
</style></head> <body class="container" style="padding:24px;max-width:900px" data-astro-cid-ztig7rse> <div class="topbar" data-astro-cid-ztig7rse> <div class="inner" data-astro-cid-ztig7rse> <a class="btn" href="/pages/" aria-label="홈으로" data-astro-cid-ztig7rse>← 홈</a> <a class="btn" id="source" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 보기</a> </div> </div> <div class="wrap" data-astro-cid-ztig7rse> <h1 style="margin:10px 0 6px" data-astro-cid-ztig7rse></h1> <div class="hero" id="hero" data-astro-cid-ztig7rse><img alt="" id="heroImg" loading="eager" data-astro-cid-ztig7rse></div> <div class="actions" data-astro-cid-ztig7rse> <a class="btn primary" id="ctaSource" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 바로가기</a> </div> <article data-astro-cid-ztig7rse> <h1 id="폰트-복제-ai---calligrapher">폰트 복제 AI - Calligrapher</h1>
<p>발견일: 2025/07/07
원문 URL: <a href="https://github.com/Calligrapher2025/Calligrapher">https://github.com/Calligrapher2025/Calligrapher</a>
분류: 오픈소스
원문 Source: 🔗github
즐겨찾기: No</p>
<p><a href="https://opengraph.githubassets.com/8a972e2dd6ece6346cc793e0f945483e2740e8ea93fd2148f228280cdd9966cc/Calligrapher2025/Calligrapher"></a></p>
<h1 id="calligrapher-freestyle-text-image-customization">Calligrapher: Freestyle Text Image Customization</h1>
<p>서예가: 자유형 텍스트 이미지 사용자 정의</p>
<blockquote>
<p><strong>Calligrapher: Freestyle Text Image Customization</strong>
<strong>서예가: 자유형 텍스트 이미지 사용자 정의</strong></p>
</blockquote>
<p><img src="https://github.com/Calligrapher2025/Calligrapher/raw/main/docs/static/images/teaser.jpg" alt=""></p>
<p><strong>Figure:</strong> Photorealistic text image customization results produced by our proposed Calligrapher, which allows users to perform customization with diverse stylized images and text prompts.
<strong>숫자:</strong> 우리가 제안한 Calligrapher가 생성한 사실적인 텍스트 이미지 사용자 정의 결과를 통해 사용자는 다양한 양식화된 이미지와 텍스트 프롬프트로 사용자 정의를 수행할 수 있습니다.</p>
<p><img src="https://github.com/Calligrapher2025/Calligrapher/raw/main/docs/static/images/multilingual_samples.png" alt=""></p>
<p><strong>Figure:</strong> Multilingual freestyle text customization results are shown in the below figure, where tested languages and text are: Chinese (你好朋友/夏天来了), Korean (서예가), and Japanese (ナルト).
<strong>숫자:</strong> 다국어 자유형 텍스트 사용자 지정 결과는 아래 그림에 표시되어 있으며, 테스트된 언어와 텍스트는 중국어(你好朋友/夏天来了), 한국어(서예가) 및 일본어(ナルト)입니다.</p>
<h2 id="-links--resources">🔗 <strong>Links &#x26; Resources</strong></h2>
<p>🔗 <strong>링크 및 리소스</strong></p>
<p><strong>[<a href="https://calligrapher2025.github.io/Calligrapher/">📄 Project Page</a>]</strong> <strong>[<a href="https://youtu.be/FLSPphkylQE">🎥 Video</a>]</strong> <strong>[<a href="https://huggingface.co/Calligrapher2025/Calligrapher">📦 Model &#x26; Data</a>]</strong> <strong>[<a href="https://huggingface.co/spaces/Calligrapher2025/Calligrapher">🤗 Hugging Face Demo</a>]</strong> <strong>[<a href="https://huggingface.co/spaces/SahilCarterr/Calligrapher">Demo2</a>]</strong>
<strong>[</strong> <a href="https://calligrapher2025.github.io/Calligrapher/">**📄 프로젝트 페이지</a>]<strong><strong>[** <a href="https://youtu.be/FLSPphkylQE">**🎥 비디오</a>]</strong></strong>[** <a href="https://huggingface.co/Calligrapher2025/Calligrapher">**📦 모델 및 데이터</a>]<strong><strong>[** <a href="https://huggingface.co/spaces/Calligrapher2025/Calligrapher">**🤗 포옹 얼굴 데모</a>]</strong></strong>[<a href="https://huggingface.co/spaces/SahilCarterr/Calligrapher">데모2</a>]**</p>
<h2 id="summary-요약">Summary 요약</h2>
<p>We introduce Calligrapher, a novel diffusion-based framework that innovatively integrates advanced text customization with artistic typography for digital calligraphy and design applications. Addressing the challenges of precise style control and data dependency in typographic customization, our framework supports text customization under various settings including self-reference, cross-reference, and non-text reference customization. By automating high-quality, visually consistent typography, Calligrapher empowers creative practitioners in digital art, branding, and contextual typographic design.
디지털 서예 및 디자인 애플리케이션을 위한 고급 텍스트 사용자 정의와 예술적 타이포그래피를 혁신적으로 통합하는 새로운 확산 기반 프레임워크인 Calligrapher를 소개합니다. 타이포그래피 사용자 정의에서 정확한 스타일 제어 및 데이터 종속성 문제를 해결하기 위해 당사 프레임워크는 자체 참조, 상호 참조 및 비텍스트 참조 사용자 정의를 포함한 다양한 설정에서 텍스트 사용자 정의를 지원합니다. 고품질의 시각적으로 일관된 타이포그래피를 자동화함으로써 Calligrapher는 디지털 아트, 브랜딩 및 상황에 맞는 타이포그래피 디자인 분야의 창의적인 실무자에게 힘을 실어줍니다.</p>
<p><img src="https://github.com/Calligrapher2025/Calligrapher/raw/main/docs/static/images/framework.jpg" alt=""></p>
<p><strong>Figure:</strong> Training framework of Calligrapher, demonstrating the integration of localized style injection and diffusion-based learning.
<strong>숫자:</strong> 현지화된 스타일 주입과 확산 기반 학습의 통합을 보여주는 Calligrapher의 교육 프레임워크입니다.</p>
<h2 id="environment-setup-환경-설정">Environment Setup 환경 설정</h2>
<p>We provide two ways to set up the environment:
환경을 설정하는 두 가지 방법을 제공합니다.</p>
<h3 id="using-pip-pip-사용">Using pip pip 사용</h3>
<p>Requires Python 3.10 + PyTorch 2.5.0 + CUDA. Install the required dependencies using:
Python 3.10 + PyTorch 2.5.0 + CUDA가 필요합니다. 다음을 사용하여 필요한 종속성을 설치합니다.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pip install -r requirements.txt</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="using-conda-conda-사용">Using Conda Conda 사용</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>conda env create -f env.yml</span></span>
<span class="line"><span>conda activate calligrapher</span></span>
<span class="line"><span></span></span></code></pre>
<h2 id="pretrained-models--data-benchmark">Pretrained Models &#x26; Data (Benchmark)</h2>
<p>사전 훈련된 모델 및 데이터(벤치마크)</p>
<p>Before running the demos, please download the required pretrained models and test data.
데모를 실행하기 전에 필요한 사전 학습된 모델과 테스트 데이터를 다운로드하세요.</p>
<p>Download the models and testing bench using huggingface_hub:
다음을 사용하여 모델 및 테스트 벤치를 다운로드huggingface_hub.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>from huggingface_hub import snapshot_download</span></span>
<span class="line"><span># Download the base model FLUX.1-Fill-dev (granted access needed)</span></span>
<span class="line"><span>snapshot_download("black-forest-labs/FLUX.1-Fill-dev", token="your_token")</span></span>
<span class="line"><span># Download SigLIP image encoder (this model can also be automatically downloaded when running the code)</span></span>
<span class="line"><span>snapshot_download("google/siglip-so400m-patch14-384")</span></span>
<span class="line"><span># Download Calligrapher model and test data</span></span>
<span class="line"><span>snapshot_download("Calligrapher2025/Calligrapher")</span></span>
<span class="line"><span></span></span></code></pre>
<p>Or manually download from: <a href="https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev">FLUX.1-Fill-dev</a>, <a href="https://huggingface.co/google/siglip-so400m-patch14-384">SigLIP</a>, and <a href="https://huggingface.co/Calligrapher2025/Calligrapher">Calligrapher</a>.
또는 다음에서 수동으로 다운로드합니다. <a href="https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev">FLUX.1-채우기 개발</a>, <a href="https://huggingface.co/google/siglip-so400m-patch14-384">SigLIP</a> 및 <a href="https://huggingface.co/Calligrapher2025/Calligrapher">서예가</a>.</p>
<p>The Calligrapher repository hosted on Huggingface contains:
Huggingface에서 호스팅되는 Calligrapher 저장소에는 다음이 포함됩니다.</p>
<ul>
<li><code>calligrapher.bin</code>: Model weights.
<code>calligrapher.bin</code>: 가중치를 모델링합니다.</li>
<li><code>Calligrapher_bench_testing.zip</code>: Test dataset with examples for both self-reference customization and cross-reference customization scenarios. Additional reference images could also be found in it.
<code>Calligrapher_bench_testing.zip</code> : 자체 참조 사용자 지정 및 상호 참조 사용자 지정 시나리오 모두에 대한 예제가 포함된 테스트 데이터 세트입니다. 추가 참조 이미지도 찾을 수 있습니다.</li>
</ul>
<h2 id="model-usage-모델-사용">Model Usage 모델 사용</h2>
<h3 id="1path-configuration-1-경로-구성">1.Path Configuration 1. 경로 구성</h3>
<p>Before running the models, you need to configure the paths in <code>path_dict.json</code>:
모델을 실행하기 전에 <code>path_dict.json</code>에서 경로를 구성해야 합니다.</p>
<ul>
<li><code>data_dir</code>: Path to store the test dataset.
<code>data_dir</code>: 테스트 데이터 세트를 저장할 경로입니다.</li>
<li><code>cli_save_dir</code>: Path to save results from command-line interface experiments.
<code>cli_save_dir</code>: 명령줄 인터페이스 실험의 결과를 저장하는 경로입니다.</li>
<li><code>gradio_save_dir</code>: Path to save results from Gradio interface experiments.
<code>gradio_save_dir</code>: Gradio 인터페이스 실험의 결과를 저장하는 경로입니다.</li>
<li><code>gradio_temp_dir</code>: Path to save temporary files.
<code>gradio_temp_dir</code>: 임시 파일을 저장할 경로입니다.</li>
<li><code>base_model_path</code>: Path to the base model FLUX.1-Fill-dev.
<code>base_model_path</code>: 기본 모델 FLUX.1-Fill-dev의 경로입니다.</li>
<li><code>image_encoder_path</code>: Path to the SigLIP image encoder model.
<code>image_encoder_path</code>: SigLIP 이미지 인코더 모델의 경로입니다.</li>
<li><code>calligrapher_path</code>: Path to the Calligrapher model weights.
<code>calligrapher_path</code>: 서예가 모델 가중치의 경로입니다.</li>
</ul>
<h3 id="2-gradio-demo-interface-recommended">2. Gradio Demo Interface (Recommended)</h3>
<ol start="2">
<li>Gradio 데모 인터페이스(권장)</li>
</ol>
<p>We provide two Gradio demo interfaces:
우리는 두 가지 Gradio 데모 인터페이스를 제공합니다.</p>
<ol>
<li>Basic version: 기본 버전:</li>
</ol>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>python gradio_demo.py</span></span>
<span class="line"><span></span></span></code></pre>
<p>When using this demo, in addition to uploading source and reference images, users also need to use the Draw button (brush control) in the Image Editing Panel to manually draw the mask.
이 데모를 사용할 때 사용자는 소스 및 참조 이미지를 업로드하는 것 외에도 이미지 편집 패널의 그리기 버튼(브러시 컨트롤)을 사용하여 마스크를 수동으로 그려야 합니다.</p>
<ol>
<li>Version supporting uploading custom inpainting masks:
사용자 정의 인페인팅 마스크 업로드를 지원하는 버전:</li>
</ol>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>python gradio_demo_upload_mask.py</span></span>
<span class="line"><span></span></span></code></pre>
<p>This version includes pre-configured examples (e.g., at the bottom of the page) and is recommended for users to first understand how to use the model.
이 버전에는 사전 구성된 예제(예: 페이지 하단)가 포함되어 있으며 사용자가 먼저 모델 사용 방법을 이해하는 것이 좋습니다.</p>
<p>Below is a preview of the two aforementioned Gradio demo interfaces:
다음은 앞서 언급한 두 가지 Gradio 데모 인터페이스의 미리보기입니다.</p>
<p><img src="https://github.com/Calligrapher2025/Calligrapher/raw/main/docs/static/images/gradio_preview.png" alt=""></p>
<ol>
<li>Version supporting multilingual text customization such as Chinese, which is supported by <a href="https://github.com/yyyyyxie/textflux">TextFLUX</a>. To use this gradio demo, first download <a href="https://huggingface.co/yyyyyxie/textflux-lora/blob/main/pytorch_lora_weights.safetensors">TextFLUX weights</a> and configure the “textflux_path” entry in “path_dict.json”. Then download <a href="https://github.com/yyyyyxie/textflux/blob/main/resource/font/Arial-Unicode-Regular.ttf">the font resource</a> to ”./resources/” and run:
<a href="https://github.com/yyyyyxie/textflux">TextFLUX</a>에서 지원하는 중국어와 같은 다국어 텍스트 사용자 정의를 지원하는 버전입니다. 이 gradio 데모를 사용하려면 먼저 <a href="https://huggingface.co/yyyyyxie/textflux-lora/blob/main/pytorch_lora_weights.safetensors">TextFLUX 가중치</a>를 다운로드하고 “path_dict.json”에서 “textflux_path” 항목을 구성하십시오. 그런 다음 <a href="https://github.com/yyyyyxie/textflux/blob/main/resource/font/Arial-Unicode-Regular.ttf">글꼴 리소스를</a> ”./resources/“에 다운로드하고 다음을 실행합니다.</li>
</ol>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>python gradio_demo_multilingual.py</span></span>
<span class="line"><span></span></span></code></pre>
<p><strong>✨User Tips: ✨사용자 팁:</strong></p>
<ol>
<li><strong>Quality of multilingual generation.</strong> The implementation strategy combines Calligrapher with the fine-tuned base model (textflux) without additional fine-tuning, please temper expectations regarding output quality.
<strong>다국어 생성의 품질.</strong> 구현 전략은 추가 미세 조정 없이 Calligrapher와 미세 조정된 기본 모델(textflux)을 결합하므로 출력 품질에 대한 기대치를 완화하십시오.</li>
<li><strong>Speed vs Quality Trade-off.</strong> Use fewer steps (e.g., 10-step which takes ~4s/image on a single A6000 GPU) for faster generation, but quality may be lower.
<strong>속도와 품질 절충.</strong> 더 빠른 생성을 위해 더 적은 단계(예: 단일 A6000 GPU에서 이미지당 ~4초가 소요되는 10단계)를 사용하지만 품질은 낮아질 수 있습니다.</li>
<li><strong>Inpaint Position Freedom.</strong> Inpainting positions are flexible - they don’t necessarily need to match the original text locations in the input image.
<strong>인페인트 위치 자유.</strong> 인페인팅 위치는 유연하며 입력 이미지의 원본 텍스트 위치와 반드시 일치할 필요는 없습니다.</li>
<li><strong>Iterative Editing.</strong> Drag outputs from the gallery to the Image Editing Panel (clean the Editing Panel first) for quick refinements.
<strong>반복 편집.</strong> 빠른 세분화를 위해 갤러리에서 이미지 편집 패널로 출력을 드래그합니다(먼저 편집 패널 정리).</li>
<li><strong>Mask Optimization.</strong> Adjust mask size/aspect ratio to match your desired content. The model tends to fill the masks, and harmonizes the generation with background in terms of color and lighting.
<strong>마스크 최적화.</strong> 원하는 콘텐츠에 맞게 마스크 크기/종횡비를 조정하세요. 모델은 마스크를 채우는 경향이 있으며 색상과 조명 측면에서 배경과 세대를 조화시킵니다.</li>
<li><strong>Reference Image Tip.</strong> White-background references improve style consistency - the encoder also considers background context of the given reference image.
<strong>참조 이미지 팁.</strong> 흰색 배경 참조는 스타일 일관성을 향상시킵니다 - 인코더는 주어진 참조 이미지의 배경 컨텍스트도 고려합니다.</li>
<li><strong>Resolution Balance.</strong> Very high-resolution generation sometimes triggers spelling errors. 512/768px are recommended considering the model is trained under the resolution of 512.
<strong>해상도 균형.</strong> 매우 높은 해상도를 생성하면 때때로 철자 오류가 발생합니다. 512/768px는 모델이 512의 해상도로 훈련된다는 점을 고려할 때 권장됩니다.</li>
</ol>
<h3 id="3-batch-testing-cli-3-배치-테스트cli">3. Batch Testing (CLI) 3. 배치 테스트(CLI)</h3>
<p>We provide two python scripts for two text image customization modes:
두 가지 텍스트 이미지 사용자 지정 모드에 대해 두 개의 Python 스크립트를 제공합니다.</p>
<ol>
<li>Self-reference Customization:
자체 참조 사용자 정의:</li>
</ol>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>python infer_calligrapher_self_custom.py</span></span>
<span class="line"><span></span></span></code></pre>
<ol>
<li>Cross-reference Customization:
상호 참조 사용자 정의:</li>
</ol>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>python infer_calligrapher_cross_custom.py</span></span>
<span class="line"><span></span></span></code></pre>
<h2 id="additional-results-추가-결과">Additional Results 추가 결과</h2>
<p><img src="https://github.com/Calligrapher2025/Calligrapher/raw/main/docs/static/images/application.jpg" alt=""></p>
<p><strong>Figure:</strong> Qualitative results of Calligrapher under various settings. We demonstrate text customization results respectively under settings of (a) self-reference, (b) cross-reference, and (c) non-text reference. Reference-based image generation results are also incorporated in (d).
<strong>숫자:</strong> 다양한 설정에서 서예가의 질적 결과. (a) 자체 참조, (b) 상호 참조 및 (c) 비텍스트 참조 설정에서 각각 텍스트 사용자 정의 결과를 보여줍니다. 참조 기반 이미지 생성 결과도 (d)에 통합되어 있습니다.</p> </article> </div> <script type="module">
      // 목적: index.json에서 현재 글 메타/썸네일을 찾아 상세 화면에 반영한다.
      async function hydrateMeta() {
        try {
          const BASE = import.meta.env.BASE_URL;
          const slug = decodeURIComponent(location.pathname.replace(/.*\/post\//,'').replace(/\/?$/,''));
          const res = await fetch(`${BASE}index.json`);
          const data = await res.json();
          const items = (data && data.items) || [];
          const item = items.find((i) => i.slug === slug);
          if (!item) return;

          const hero = document.getElementById('hero');
          const heroImg = document.getElementById('heroImg');
          const source = document.getElementById('source');
          const cta = document.getElementById('ctaSource');
          if (item.thumbnail && hero && heroImg) {
            heroImg.setAttribute('src', item.thumbnail);
            hero.style.display = 'block';
          }
          if (item.source_url && source && cta) {
            source.setAttribute('href', item.source_url);
            cta.setAttribute('href', item.source_url);
            source.style.display='inline-block';
            cta.style.display='inline-block';
          }
        } catch {}
      }
      hydrateMeta();

      // 복사 버튼 제거됨 — 상단에 원문 보기 버튼만 유지
    </script> </body> </html>