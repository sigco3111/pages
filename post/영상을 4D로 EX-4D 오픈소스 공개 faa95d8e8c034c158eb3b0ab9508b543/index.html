<!DOCTYPE html><html lang="ko" data-astro-cid-ztig7rse> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>상세</title><link rel="icon" href="/pages/favicon.svg" type="image/svg+xml"><link rel="icon" href="/pages/favicon-32x32.png" sizes="32x32"><link rel="apple-touch-icon" href="/pages/apple-touch-icon.png" sizes="180x180"><style>:root{color-scheme:light dark}body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}.wrap[data-astro-cid-ztig7rse]{max-width:860px;margin:0 auto;padding:20px}.topbar[data-astro-cid-ztig7rse]{position:sticky;top:0;backdrop-filter:blur(6px);background:color-mix(in oklab,canvas,transparent 35%);border-bottom:1px solid color-mix(in oklab,canvastext,transparent 90%);z-index:10}.topbar[data-astro-cid-ztig7rse] .inner[data-astro-cid-ztig7rse]{display:flex;align-items:center;gap:8px;padding:10px 20px;max-width:860px;margin:0 auto}.btn[data-astro-cid-ztig7rse]{appearance:none;border:1px solid color-mix(in oklab,canvastext,transparent 85%);background:transparent;color:inherit;border-radius:10px;padding:8px 12px;cursor:pointer;font-size:14px}.btn[data-astro-cid-ztig7rse].primary{background:#111827;color:#fff;border-color:#111827}@media (prefers-color-scheme: dark){.btn[data-astro-cid-ztig7rse].primary{background:#e5e7eb;color:#111827;border-color:#e5e7eb}}.hero[data-astro-cid-ztig7rse]{margin:14px 0 8px;display:none}.hero[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{width:100%;height:auto;border-radius:12px;display:block;background:#f3f4f6}article[data-astro-cid-ztig7rse]{line-height:1.72;font-size:16px}article[data-astro-cid-ztig7rse] :is(h1,h2,h3)[data-astro-cid-ztig7rse]{line-height:1.25;margin:24px 0 10px}article[data-astro-cid-ztig7rse] h1[data-astro-cid-ztig7rse]{font-size:28px}article[data-astro-cid-ztig7rse] h2[data-astro-cid-ztig7rse]{font-size:22px}article[data-astro-cid-ztig7rse] h3[data-astro-cid-ztig7rse]{font-size:18px}article[data-astro-cid-ztig7rse] p[data-astro-cid-ztig7rse]{margin:10px 0}article[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{max-width:100%;height:auto;border-radius:8px;background:#f3f4f6}article[data-astro-cid-ztig7rse] pre[data-astro-cid-ztig7rse]{overflow:auto;padding:14px;border:1px solid color-mix(in oklab,canvastext,transparent 90%);border-radius:10px;background:color-mix(in oklab,canvastext,transparent 96%)}article[data-astro-cid-ztig7rse] code[data-astro-cid-ztig7rse]:not(pre code){background:color-mix(in oklab,canvastext,transparent 94%);padding:2px 6px;border-radius:6px}article[data-astro-cid-ztig7rse] blockquote[data-astro-cid-ztig7rse]{border-left:3px solid #9CA3AF;margin:8px 0;padding:4px 12px;color:#6b7280}.actions[data-astro-cid-ztig7rse]{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0 18px}
</style></head> <body class="container" style="padding:24px;max-width:900px" data-astro-cid-ztig7rse> <div class="topbar" data-astro-cid-ztig7rse> <div class="inner" data-astro-cid-ztig7rse> <a class="btn" href="/pages/" aria-label="홈으로" data-astro-cid-ztig7rse>← 홈</a> <a class="btn" id="source" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 보기</a> </div> </div> <div class="wrap" data-astro-cid-ztig7rse> <h1 style="margin:10px 0 6px" data-astro-cid-ztig7rse></h1> <div class="hero" id="hero" data-astro-cid-ztig7rse><img alt="" id="heroImg" loading="eager" data-astro-cid-ztig7rse></div> <div class="actions" data-astro-cid-ztig7rse> <a class="btn primary" id="ctaSource" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 바로가기</a> </div> <article data-astro-cid-ztig7rse> <h1 id="영상을-4d로-ex-4d-오픈소스-공개">영상을 4D로 EX-4D 오픈소스 공개</h1>
<p>발견일: 2025/07/08
원문 URL: <a href="https://github.com/tau-yihouxiang/EX-4D">https://github.com/tau-yihouxiang/EX-4D</a>
분류: 오픈소스
원문 Source: 🔗github
즐겨찾기: No</p>
<p><a href="https://opengraph.githubassets.com/2f3fe93325ec8e6d2c7151c068a08c6b7ac6b334b4b5e5dce97b699b839e68ca/tau-yihouxiang/EX-4D"></a></p>
<h1 id="ex-4d-extreme-viewpoint-4d-video-synthesis-via-depth-watertight-mesh">EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh</h1>
<p>EX-4D: 심도 방수 메시를 통한 EXtreme Viewpoint 4D 비디오 합성</p>
<p><img src="https://github.com/tau-yihouxiang/EX-4D/raw/main/docs/Logo.png" alt=""></p>
<p><a href="https://arxiv.org/abs/2506.05554">📄 Paper</a> | <a href="https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html">🎥 Homepage</a> | <a href="https://github.com/tau-yihouxiang/EX-4D">💻 Code</a>
<a href="https://arxiv.org/abs/2506.05554">📄 종이</a> | <a href="https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html">🎥 홈페이지</a> | <a href="https://github.com/tau-yihouxiang/EX-4D">💻 코드</a></p>
<h2 id="-highlights--하이라이트">🌟 Highlights 🌟 하이라이트</h2>
<ul>
<li><strong>🎯 Extreme Viewpoint Synthesis</strong>: Generate high-quality 4D videos with camera movements ranging from -90° to 90°
<strong>🎯 극한의 시점 합성</strong>: -90°에서 90° 범위의 카메라 움직임으로 고품질 4D 비디오 생성</li>
<li><strong>🔧 Depth Watertight Mesh</strong>: Novel geometric representation that models both visible and occluded regions
<strong>🔧 Depth Watertight Mesh</strong>: 가시 영역과 가려진 영역을 모두 모델링하는 새로운 기하학적 표현</li>
<li><strong>⚡ Lightweight Architecture</strong>: Only 1% trainable parameters (140M) of the 14B video diffusion backbone
<strong>⚡ 경량 아키텍처</strong>: 14B 비디오 확산 백본의 1% 학습 가능 매개변수(140M)만</li>
<li><strong>🎭 No Multi-view Training</strong>: Innovative masking strategy eliminates the need for expensive multi-view datasets
<strong>🎭 멀티뷰 교육 없음</strong>: 혁신적인 마스킹 전략으로 값비싼 멀티뷰 데이터 세트가 필요하지 않습니다.</li>
<li><strong>🏆 State-of-the-art Performance</strong>: Outperforms existing methods, especially on extreme camera angles
<strong>🏆 최첨단 성능</strong>: 특히 극한의 카메라 각도에서 기존 방법을 능가합니다.</li>
</ul>
<h2 id="-demo-results--데모-결과">🎬 Demo Results 🎬 데모 결과</h2>
<p><img src="https://github.com/tau-yihouxiang/EX-4D/raw/main/docs/teaser.png" alt=""></p>
<p><em>EX-4D transforms monocular videos into camera-controllable 4D experiences with physically consistent results under extreme viewpoints.</em>
<em>EX-4D는 단안 비디오를 카메라로 제어할 수 있는 4D 경험으로 변환하여 극한의 시점에서 물리적으로 일관된 결과를 제공합니다.</em></p>
<h2 id="️-framework-overview-️-프레임워크-개요">🏗️ Framework Overview 🏗️ 프레임워크 개요</h2>
<p><img src="https://github.com/tau-yihouxiang/EX-4D/raw/main/docs/overview.png" alt=""></p>
<p>Our framework consists of three key components:
우리의 프레임워크는 세 가지 주요 구성 요소로 구성됩니다.</p>
<ol>
<li><strong>🔺 Depth Watertight Mesh Construction</strong>: Creates a robust geometric prior that explicitly models both visible and occluded regions
<strong>🔺 Depth Watertight Mesh Construction</strong>: 가시 영역과 가려진 영역을 모두 명시적으로 모델링하는 강력한 기하학적 사전 설정을 생성합니다</li>
<li><strong>🎭 Simulated Masking Strategy</strong>: Generates effective training data from monocular videos without multi-view datasets
<strong>🎭 시뮬레이션된 마스킹 전략</strong>: 다중 뷰 데이터 세트 없이 단안 비디오에서 효과적인 훈련 데이터 생성</li>
<li><strong>⚙️ Lightweight LoRA Adapter</strong>: Efficiently integrates geometric information with pre-trained video diffusion models
<strong>⚙️ 경량 LoRA 어댑터</strong>: 기하학적 정보를 사전 훈련된 비디오 확산 모델과 효율적으로 통합합니다.</li>
</ol>
<h2 id="-quick-start--빠른-시작">🚀 Quick Start 🚀 빠른 시작</h2>
<h3 id="installation-설치">Installation 설치</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span># Clone the repository</span></span>
<span class="line"><span>git clone https://github.com/tau-yihouxiang/EX-4D.git</span></span>
<span class="line"><span>cd EX-4D</span></span>
<span class="line"><span># Create conda environment</span></span>
<span class="line"><span>conda create -n ex4d python=3.10</span></span>
<span class="line"><span>conda activate ex4d</span></span>
<span class="line"><span># Install PyTorch (2.x recommended)</span></span>
<span class="line"><span>pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124</span></span>
<span class="line"><span># Install Nvdiffrast</span></span>
<span class="line"><span>pip install git+https://github.com/NVlabs/nvdiffrast.git</span></span>
<span class="line"><span># Install dependencies and diffsynth</span></span>
<span class="line"><span>pip install -e .</span></span>
<span class="line"><span># Install depthcrafter for depth estimation. (Follow DepthCrafter's installing instruction for checkpoints preparation.)</span></span>
<span class="line"><span>git clone https://github.com/Tencent/DepthCrafter.git</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="download-pretrained-model">Download Pretrained Model</h3>
<p>사전 학습된 모델 다운로드</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>huggingface-cli download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./models/Wan-AI</span></span>
<span class="line"><span>huggingface-cli download yihouxiang/EX-4D --local-dir ./models/EX-4D</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="example-usage-사용-예">Example Usage 사용 예</h3>
<h3 id="1-dw-mesh-reconstruction">1. DW-Mesh Reconstruction</h3>
<ol>
<li>DW-메쉬 재구성</li>
</ol>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span># --cam 180 (30 / 60 / 90 / zoom_in / zoom_out )</span></span>
<span class="line"><span>python recon.py --input_video examples/flower/input.mp4 --cam 180 --output_dir outputs/flower --save_mesh</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="2-ex-4d-generation-48gb-vram-required">2. EX-4D Generation (48GB VRAM required)</h3>
<ol start="2">
<li>EX-4D 세대(48GB VRAM 필요)</li>
</ol>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>python generate.py --color_video outputs/flower/color_180.mp4 --mask_video outputs/flower/mask_180.mp4 --output_video outputs/flower/output.mp4</span></span>
<span class="line"><span></span></span></code></pre>
<p><strong>Input Video</strong></p>
<p><img src="https://github.com/tau-yihouxiang/EX-4D/raw/main/examples/flower/input.gif" alt=""></p>
<p>➜</p>
<p><strong>Output Video</strong></p>
<p><img src="https://github.com/tau-yihouxiang/EX-4D/raw/main/examples/flower/output.gif" alt=""></p>
<h3 id="user-study-results">User Study Results</h3>
<ul>
<li><strong>70.7%</strong> of participants preferred EX-4D over baseline methods</li>
<li>Superior performance in physical consistency and extreme viewpoint quality</li>
<li>Significant improvement as camera angles become more extreme</li>
</ul>
<h2 id="-applications">🎯 Applications</h2>
<ul>
<li><strong>🎮 Gaming</strong>: Create immersive 3D game cinematics from 2D footage</li>
<li><strong>🎬 Film Production</strong>: Generate novel camera angles for post-production</li>
<li><strong>🥽 VR/AR</strong>: Create free-viewpoint video experiences</li>
<li><strong>📱 Social Media</strong>: Generate dynamic camera movements for content creation</li>
<li><strong>🏢 Architecture</strong>: Visualize spaces from multiple viewpoints</li>
</ul>
<h2 id="️-limitations">⚠️ Limitations</h2>
<ul>
<li><strong>Depth Dependency</strong>: Performance relies on monocular depth estimation quality</li>
<li><strong>Computational Cost</strong>: Requires significant computation for high-resolution videos</li>
<li><strong>Reflective Surfaces</strong>: Challenges with reflective or transparent materials</li>
</ul>
<h2 id="-future-work">🔮 Future Work</h2>
<ul>
<li>Real-time inference optimization (3DGS / 4DGS)</li>
<li>Support for higher resolutions (1K, 2K)</li>
<li>Neural mesh refinement techniques</li>
</ul>
<h2 id="-acknowledgments">🙏 Acknowledgments</h2>
<p>We would like to thank the <a href="https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1">DiffSynth-Studio v1.1.1</a> project for providing the foundational diffusion framework.</p>
<h2 id="-citation">📚 Citation</h2>
<p>If you find our work useful, please consider citing:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>@misc{hu2025ex4dextremeviewpoint4d,</span></span>
<span class="line"><span>      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, </span></span>
<span class="line"><span>      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},</span></span>
<span class="line"><span>      year={2025},</span></span>
<span class="line"><span>      eprint={2506.05554},</span></span>
<span class="line"><span>      archivePrefix={arXiv},</span></span>
<span class="line"><span>      primaryClass={cs.CV},</span></span>
<span class="line"><span>      url={https://arxiv.org/abs/2506.05554}, </span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span></code></pre> </article> </div> <script type="module">
      // 목적: index.json에서 현재 글 메타/썸네일을 찾아 상세 화면에 반영한다.
      async function hydrateMeta() {
        try {
          const BASE = import.meta.env.BASE_URL;
          const slug = decodeURIComponent(location.pathname.replace(/.*\/post\//,'').replace(/\/?$/,''));
          const res = await fetch(`${BASE}index.json`);
          const data = await res.json();
          const items = (data && data.items) || [];
          const item = items.find((i) => i.slug === slug);
          if (!item) return;

          const hero = document.getElementById('hero');
          const heroImg = document.getElementById('heroImg');
          const source = document.getElementById('source');
          const cta = document.getElementById('ctaSource');
          if (item.thumbnail && hero && heroImg) {
            heroImg.setAttribute('src', item.thumbnail);
            hero.style.display = 'block';
          }
          if (item.source_url && source && cta) {
            source.setAttribute('href', item.source_url);
            cta.setAttribute('href', item.source_url);
            source.style.display='inline-block';
            cta.style.display='inline-block';
          }
        } catch {}
      }
      hydrateMeta();

      // 복사 버튼 제거됨 — 상단에 원문 보기 버튼만 유지
    </script> </body> </html>