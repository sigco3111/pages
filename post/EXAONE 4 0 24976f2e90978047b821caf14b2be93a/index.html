<!DOCTYPE html><html lang="ko" data-astro-cid-ztig7rse> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>상세</title><link rel="icon" href="/pages/favicon.svg" type="image/svg+xml"><link rel="icon" href="/pages/favicon-32x32.png" sizes="32x32"><link rel="apple-touch-icon" href="/pages/apple-touch-icon.png" sizes="180x180"><style>:root{color-scheme:light dark}body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}.wrap[data-astro-cid-ztig7rse]{max-width:860px;margin:0 auto;padding:20px}.topbar[data-astro-cid-ztig7rse]{position:sticky;top:0;backdrop-filter:blur(6px);background:color-mix(in oklab,canvas,transparent 35%);border-bottom:1px solid color-mix(in oklab,canvastext,transparent 90%);z-index:10}.topbar[data-astro-cid-ztig7rse] .inner[data-astro-cid-ztig7rse]{display:flex;align-items:center;gap:8px;padding:10px 20px;max-width:860px;margin:0 auto}.btn[data-astro-cid-ztig7rse]{appearance:none;border:1px solid color-mix(in oklab,canvastext,transparent 85%);background:transparent;color:inherit;border-radius:10px;padding:8px 12px;cursor:pointer;font-size:14px}.btn[data-astro-cid-ztig7rse].primary{background:#111827;color:#fff;border-color:#111827}@media (prefers-color-scheme: dark){.btn[data-astro-cid-ztig7rse].primary{background:#e5e7eb;color:#111827;border-color:#e5e7eb}}.hero[data-astro-cid-ztig7rse]{margin:14px 0 8px;display:none}.hero[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{width:100%;height:auto;border-radius:12px;display:block;background:#f3f4f6}article[data-astro-cid-ztig7rse]{line-height:1.72;font-size:16px}article[data-astro-cid-ztig7rse] :is(h1,h2,h3)[data-astro-cid-ztig7rse]{line-height:1.25;margin:24px 0 10px}article[data-astro-cid-ztig7rse] h1[data-astro-cid-ztig7rse]{font-size:28px}article[data-astro-cid-ztig7rse] h2[data-astro-cid-ztig7rse]{font-size:22px}article[data-astro-cid-ztig7rse] h3[data-astro-cid-ztig7rse]{font-size:18px}article[data-astro-cid-ztig7rse] p[data-astro-cid-ztig7rse]{margin:10px 0}article[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{max-width:100%;height:auto;border-radius:8px;background:#f3f4f6}article[data-astro-cid-ztig7rse] pre[data-astro-cid-ztig7rse]{overflow:auto;padding:14px;border:1px solid color-mix(in oklab,canvastext,transparent 90%);border-radius:10px;background:color-mix(in oklab,canvastext,transparent 96%)}article[data-astro-cid-ztig7rse] code[data-astro-cid-ztig7rse]:not(pre code){background:color-mix(in oklab,canvastext,transparent 94%);padding:2px 6px;border-radius:6px}article[data-astro-cid-ztig7rse] blockquote[data-astro-cid-ztig7rse]{border-left:3px solid #9CA3AF;margin:8px 0;padding:4px 12px;color:#6b7280}.actions[data-astro-cid-ztig7rse]{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0 18px}
</style></head> <body class="container" style="padding:24px;max-width:900px" data-astro-cid-ztig7rse> <div class="topbar" data-astro-cid-ztig7rse> <div class="inner" data-astro-cid-ztig7rse> <a class="btn" href="/pages/" aria-label="홈으로" data-astro-cid-ztig7rse>← 홈</a> <a class="btn" id="source" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 보기</a> </div> </div> <div class="wrap" data-astro-cid-ztig7rse> <h1 style="margin:10px 0 6px" data-astro-cid-ztig7rse></h1> <div class="hero" id="hero" data-astro-cid-ztig7rse><img alt="" id="heroImg" loading="eager" data-astro-cid-ztig7rse></div> <div class="actions" data-astro-cid-ztig7rse> <a class="btn primary" id="ctaSource" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 바로가기</a> </div> <article data-astro-cid-ztig7rse> <h1 id="exaone-40">EXAONE 4.0</h1>
<p>발견일: 2025/07/16
분류: 오픈소스
즐겨찾기: No</p>
<h1 id="exaone-40-모델-특징">EXAONE 4.0 모델 특징</h1>
<p><strong>EXAONE 4.0</strong>은 LG AI Research에서 개발한 오픈소스 대형 언어 모델(LLM)로, <strong>EXpert AI for EveryONE</strong>의 약자로 모든 이를 위한 전문 AI를 목표로 합니다. <a href="https://huggingface.co/collections/LGAI-EXAONE/exaone-40-686b2e0069800c835ed48375">Hugging Face 컬렉션</a>에서 2025년 7월 15일 공개되었으며, 영어, 한국어, 스페인어를 지원하는 다국어 모델입니다.</p>
<h2 id="주요-특징">주요 특징</h2>
<h3 id="1-모델-구성">1. 모델 구성</h3>
<ul>
<li><strong>두 가지 크기</strong>:
<ul>
<li><strong>32B(320억 파라미터)</strong>: 복잡한 추론 및 대규모 데이터 처리에 최적.</li>
<li><strong>1.2B(12억 파라미터)</strong>: 온디바이스용 경량 모델, 자원 제약 환경에 적합.</li>
</ul>
</li>
<li><strong>긴 컨텍스트</strong>: 최대 <strong>131,072 토큰</strong> 지원, 긴 문서 및 다중 턴 대화 가능.</li>
</ul>
<h3 id="2-하이브리드-추론">2. 하이브리드 추론</h3>
<ul>
<li><strong>비추론 모드</strong>: 빠른 응답, 일반 대화 및 간단한 작업에 적합.</li>
<li><strong>추론 모드</strong>: <code>\\n</code> 태그로 사고 과정 명시, 수학/코딩/문제 해결에 특화.</li>
<li><strong>하이브리드 어텐션</strong>: 로컬(슬라이딩 윈도우) 및 글로벌 어텐션(3:1) 결합.</li>
</ul>
<h3 id="3-다국어-지원">3. 다국어 지원</h3>
<ul>
<li>영어, 한국어, 스페인어 처리. 예: “Explain how wonderful you are” (영어), “너가 얼마나 대단한지 설명해 봐” (한국어).</li>
<li>다국어 대화, 문서 요약 가능.</li>
</ul>
<h3 id="4-에이전트-기능">4. 에이전트 기능</h3>
<ul>
<li>API 호출, 데이터 분석, 코드 생성 등 수행.</li>
<li>활용: 코딩, 데이터 시각화, 워크플로우 자동화.</li>
</ul>
<h3 id="5-성능">5. 성능</h3>
<ul>
<li><strong>벤치마크</strong>:
<ul>
<li><strong>MATH-500</strong>: 95.7% (EXAONE Deep 32B).</li>
<li><strong>Live Code Bench</strong>: 59.5% 성공률, OpenAI o1-mini 및 DeepSeek R1 상회.</li>
<li><strong>AIME</strong>: 고급 수학 문제 풀이 강력.</li>
</ul>
</li>
<li>긴 컨텍스트(32K~131K 토큰)로 복잡한 작업 우수.</li>
</ul>
<h3 id="6-기술적-특징">6. 기술적 특징</h3>
<ul>
<li><strong>아키텍처</strong>: 그룹 쿼리 어텐션(40 Q-heads, 8 KV-heads).</li>
<li><strong>사전 학습</strong>: 8T 토큰으로 일반화 성능 강화.</li>
<li><strong>최적화</strong>: AWQ, GGUF 양자화로 메모리 효율성 향상.</li>
</ul>
<h2 id="접근-방법">접근 방법</h2>
<ul>
<li>
<p><strong>Hugging Face</strong>: <a href="https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B">EXAONE-4.0-32B</a>, <a href="https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-1.2B">EXAONE-4.0-1.2B</a>.</p>
</li>
<li>
<p><strong>설치</strong>:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#B392F0">pip</span><span style="color:#9ECBFF"> install</span><span style="color:#9ECBFF"> git+https://github.com/lgai-exaone/transformers@add-exaone4</span></span>
<span class="line"></span>
<span class="line"></span></code></pre>
</li>
<li>
<p><strong>예제 코드</strong>:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">from</span><span style="color:#E1E4E8"> transformers </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> AutoModelForCausalLM, AutoTokenizer</span></span>
<span class="line"><span style="color:#E1E4E8">model_name </span><span style="color:#F97583">=</span><span style="color:#9ECBFF"> "LGAI-EXAONE/EXAONE-4.0-32B"</span></span>
<span class="line"><span style="color:#E1E4E8">model </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> AutoModelForCausalLM.from_pretrained(model_name, </span><span style="color:#FFAB70">torch_dtype</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"bfloat16"</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">device_map</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"auto"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#E1E4E8">tokenizer </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> AutoTokenizer.from_pretrained(model_name)</span></span>
<span class="line"><span style="color:#E1E4E8">prompt </span><span style="color:#F97583">=</span><span style="color:#9ECBFF"> "너가 얼마나 대단한지 설명해 봐"</span></span>
<span class="line"><span style="color:#E1E4E8">messages </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [{</span><span style="color:#9ECBFF">"role"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"user"</span><span style="color:#E1E4E8">, </span><span style="color:#9ECBFF">"content"</span><span style="color:#E1E4E8">: prompt}]</span></span>
<span class="line"><span style="color:#E1E4E8">input_ids </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tokenizer.apply_chat_template(messages, </span><span style="color:#FFAB70">tokenize</span><span style="color:#F97583">=</span><span style="color:#79B8FF">True</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">add_generation_prompt</span><span style="color:#F97583">=</span><span style="color:#79B8FF">True</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">return_tensors</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"pt"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#E1E4E8">output </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> model.generate(input_ids.to(model.device), </span><span style="color:#FFAB70">max_new_tokens</span><span style="color:#F97583">=</span><span style="color:#79B8FF">128</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">do_sample</span><span style="color:#F97583">=</span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#79B8FF">print</span><span style="color:#E1E4E8">(tokenizer.decode(output[</span><span style="color:#79B8FF">0</span><span style="color:#E1E4E8">]))</span></span>
<span class="line"></span>
<span class="line"></span></code></pre>
</li>
<li>
<p><strong>Ollama</strong>: GGUF 형식으로 실행 가능.</p>
</li>
<li>
<p><strong>로컬 실행</strong>: llama.cpp, TensorRT-LLM 지원(vLLM/SGLang 미지원).</p>
</li>
</ul>
<h2 id="활용-사례">활용 사례</h2>
<ul>
<li><strong>코딩</strong>: 알고리즘, 디버깅, GitHub 이슈 해결.</li>
<li><strong>수학</strong>: AIME, MATH-500 문제 풀이.</li>
<li><strong>데이터 분석</strong>: 데이터셋 처리, 시각화.</li>
<li><strong>다국어</strong>: 영어/한국어/스페인어 챗봇, 문서 요약.</li>
</ul>
<h2 id="장점">장점</h2>
<ul>
<li>오픈소스: 연구용 무료, 상업용은 <a href="mailto:contact_us@lgresearch.ai">contact_us@lgresearch.ai</a> 문의.</li>
<li>동급 모델(OpenAI o1-mini) 대비 경쟁력.</li>
<li>온디바이스(1.2B) 및 고성능(32B) 지원.</li>
<li>131K 토큰으로 장문 처리 강력.</li>
</ul>
<h2 id="한계">한계</h2>
<ul>
<li>텍스트 중심, 이미지/오디오 미지원.</li>
<li>vLLM, SGLang 미지원(2025년 7월 기준).</li>
<li>32B 모델은 고성능 GPU 필요.</li>
<li>학습 데이터 기반 잠재적 편향 가능.</li>
</ul>
<h2 id="시작하기">시작하기</h2>
<ul>
<li><strong>다운로드</strong>: <a href="https://huggingface.co/collections/LGAI-EXAONE/exaone-40-686b2e0069800c835ed48375">Hugging Face EXAONE 4.0</a>.</li>
<li><strong>문서</strong>: <a href="https://github.com/LG-AI-EXAONE/EXAONE-4.0">LG AI Research GitHub</a>, <a href="https://arxiv.org/">arXiv</a>.</li>
<li><strong>문의</strong>: <a href="mailto:contact_us@lgresearch.ai">contact_us@lgresearch.ai</a>.</li>
</ul>
<p><strong>EXAONE 4.0</strong>은 코딩, 수학, 다국어 작업에서 강력한 오픈소스 LLM으로, AI 발전에 기여합니다. <a href="https://huggingface.co/LGAI-EXAONE">Hugging Face</a>에서 확인하세요!</p> </article> </div> <script type="module">
      // 목적: index.json에서 현재 글 메타/썸네일을 찾아 상세 화면에 반영한다.
      async function hydrateMeta() {
        try {
          const BASE = import.meta.env.BASE_URL;
          const slug = decodeURIComponent(location.pathname.replace(/.*\/post\//,'').replace(/\/?$/,''));
          const res = await fetch(`${BASE}index.json`);
          const data = await res.json();
          const items = (data && data.items) || [];
          const item = items.find((i) => i.slug === slug);
          if (!item) return;

          const hero = document.getElementById('hero');
          const heroImg = document.getElementById('heroImg');
          const source = document.getElementById('source');
          const cta = document.getElementById('ctaSource');
          if (item.thumbnail && hero && heroImg) {
            heroImg.setAttribute('src', item.thumbnail);
            hero.style.display = 'block';
          }
          if (item.source_url && source && cta) {
            source.setAttribute('href', item.source_url);
            cta.setAttribute('href', item.source_url);
            source.style.display='inline-block';
            cta.style.display='inline-block';
          }
        } catch {}
      }
      hydrateMeta();

      // 복사 버튼 제거됨 — 상단에 원문 보기 버튼만 유지
    </script> </body> </html>