<!DOCTYPE html><html lang="ko" data-astro-cid-ztig7rse> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>ìƒì„¸</title><link rel="icon" href="/pages/favicon.svg" type="image/svg+xml"><link rel="icon" href="/pages/favicon-32x32.png" sizes="32x32"><link rel="apple-touch-icon" href="/pages/apple-touch-icon.png" sizes="180x180"><style>:root{color-scheme:light dark}body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}.wrap[data-astro-cid-ztig7rse]{max-width:860px;margin:0 auto;padding:20px}.topbar[data-astro-cid-ztig7rse]{position:sticky;top:0;backdrop-filter:blur(6px);background:color-mix(in oklab,canvas,transparent 35%);border-bottom:1px solid color-mix(in oklab,canvastext,transparent 90%);z-index:10}.topbar[data-astro-cid-ztig7rse] .inner[data-astro-cid-ztig7rse]{display:flex;align-items:center;gap:8px;padding:10px 20px;max-width:860px;margin:0 auto}.btn[data-astro-cid-ztig7rse]{appearance:none;border:1px solid color-mix(in oklab,canvastext,transparent 85%);background:transparent;color:inherit;border-radius:10px;padding:8px 12px;cursor:pointer;font-size:14px}.btn[data-astro-cid-ztig7rse].primary{background:#111827;color:#fff;border-color:#111827}@media (prefers-color-scheme: dark){.btn[data-astro-cid-ztig7rse].primary{background:#e5e7eb;color:#111827;border-color:#e5e7eb}}.hero[data-astro-cid-ztig7rse]{margin:14px 0 8px;display:none}.hero[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{width:100%;height:auto;border-radius:12px;display:block;background:#f3f4f6}article[data-astro-cid-ztig7rse]{line-height:1.72;font-size:16px}article[data-astro-cid-ztig7rse] :is(h1,h2,h3)[data-astro-cid-ztig7rse]{line-height:1.25;margin:24px 0 10px}article[data-astro-cid-ztig7rse] h1[data-astro-cid-ztig7rse]{font-size:28px}article[data-astro-cid-ztig7rse] h2[data-astro-cid-ztig7rse]{font-size:22px}article[data-astro-cid-ztig7rse] h3[data-astro-cid-ztig7rse]{font-size:18px}article[data-astro-cid-ztig7rse] p[data-astro-cid-ztig7rse]{margin:10px 0}article[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{max-width:100%;height:auto;border-radius:8px;background:#f3f4f6}article[data-astro-cid-ztig7rse] pre[data-astro-cid-ztig7rse]{overflow:auto;padding:14px;border:1px solid color-mix(in oklab,canvastext,transparent 90%);border-radius:10px;background:color-mix(in oklab,canvastext,transparent 96%)}article[data-astro-cid-ztig7rse] code[data-astro-cid-ztig7rse]:not(pre code){background:color-mix(in oklab,canvastext,transparent 94%);padding:2px 6px;border-radius:6px}article[data-astro-cid-ztig7rse] blockquote[data-astro-cid-ztig7rse]{border-left:3px solid #9CA3AF;margin:8px 0;padding:4px 12px;color:#6b7280}.actions[data-astro-cid-ztig7rse]{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0 18px}
</style></head> <body class="container" style="padding:24px;max-width:900px" data-astro-cid-ztig7rse> <div class="topbar" data-astro-cid-ztig7rse> <div class="inner" data-astro-cid-ztig7rse> <a class="btn" href="/pages/" aria-label="í™ˆìœ¼ë¡œ" data-astro-cid-ztig7rse>â† í™ˆ</a> <a class="btn" id="source" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>ì›ë¬¸ ë³´ê¸°</a> </div> </div> <div class="wrap" data-astro-cid-ztig7rse> <h1 style="margin:10px 0 6px" data-astro-cid-ztig7rse></h1> <div class="hero" id="hero" data-astro-cid-ztig7rse><img alt="" id="heroImg" loading="eager" data-astro-cid-ztig7rse></div> <div class="actions" data-astro-cid-ztig7rse> <a class="btn primary" id="ctaSource" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>ì›ë¬¸ ë°”ë¡œê°€ê¸°</a> </div> <article data-astro-cid-ztig7rse> <h1 id="appleì˜-diffucoder-í™•ì‚°-ëª¨ë¸ì„-ì‚¬ìš©í•œ-ì½”ë“œ-ìƒì„±">Appleì˜ DiffuCoder í™•ì‚° ëª¨ë¸ì„ ì‚¬ìš©í•œ ì½”ë“œ ìƒì„±</h1>
<p>ë°œê²¬ì¼: 2025/07/09
ì›ë¬¸ URL: <a href="https://github.com/apple/ml-diffucoder">https://github.com/apple/ml-diffucoder</a>
ë¶„ë¥˜: ì˜¤í”ˆì†ŒìŠ¤
ì›ë¬¸ Source: ğŸ”—github
ì¦ê²¨ì°¾ê¸°: No</p>
<h2 id="masked-diffusion-models-for-code-generation">Masked Diffusion Models for Code Generation</h2>
<p>ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ë§ˆìŠ¤í‚¹ëœ í™•ì‚° ëª¨ë¸</p>
<p><a href="https://camo.githubusercontent.com/f191a33a959369475e8c3743c17bdd2d069fdaee1abd8bf3cf042ebd1844e5ea/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617065722d41727869762532304c696e6b2d677265656e"></a></p>
<p><a href="https://camo.githubusercontent.com/14e900c44228cffa80904c2e05a53ca33d84a63d198c411a9f8e67b008594322/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170706c652d626c7565"></a></p>
<p><a href="https://camo.githubusercontent.com/92d7302321a11da62ca18a3261e59653a8bd21c98a0519205c134ba22eaa95c2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f48756767696e67253230466163652d4469666675436f6465725f426173652d464645423342"></a></p>
<p><a href="https://camo.githubusercontent.com/29eaa740d50677ab100f9430003418fc85f2ff2c9d98c1f756c72f7269d2c15b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f48756767696e67253230466163652d4469666675436f6465725f496e7374727563742d464645423342"></a></p>
<p><a href="https://camo.githubusercontent.com/6bae1026ea3606363463b7109ae30993b6bcac1f610a9709a5ec05d0179892f0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f48756767696e67253230466163652d4469666675436f6465725f63704752504f2d464645423342"></a></p>
<p>This software project accompanies the research paper, <a href="https://arxiv.org/abs/2506.20639">DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation</a>.
ì´ ì†Œí”„íŠ¸ì›¨ì–´ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬ ë…¼ë¬¸ì¸ <a href="https://arxiv.org/abs/2506.20639">DiffuCoder: ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ë§ˆìŠ¤í‚¹ í™•ì‚° ëª¨ë¸ ì´í•´ ë° ê°œì„ </a>ê³¼ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤.</p>
<h3 id="updates-ì—…ë°ì´íŠ¸">Updates ì—…ë°ì´íŠ¸</h3>
<p><strong>MLX support on Apple Silicon is in progress. We will make necessary updates to the repository once it is available.</strong>
<strong>Apple Siliconì—ì„œ MLX ì§€ì›ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì €ì¥ì†Œê°€ ì‚¬ìš© ê°€ëŠ¥í•´ì§€ë©´ í•„ìš”í•œ ì—…ë°ì´íŠ¸ë¥¼ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤.</strong></p>
<ul>
<li>July 8, 2025. We are still training for 14B models, to be updated.
2025ë…„ 7ì›” 8ì¼. ìš°ë¦¬ëŠ” ì—¬ì „íˆ ì—…ë°ì´íŠ¸ë  14B ëª¨ë¸ì— ëŒ€í•œ í›ˆë ¨ ì¤‘ì…ë‹ˆë‹¤.</li>
<li>July 7, 2025. <a href="https://huggingface.co/mlx-community/DiffuCoder-7B-cpGRPO-8bit">MLX community implementation of DiffuCoder 8bit model</a>
2025ë…„ 7ì›” 7ì¼. <a href="https://huggingface.co/mlx-community/DiffuCoder-7B-cpGRPO-8bit">DiffuCoder 8ë¹„íŠ¸ ëª¨ë¸ì˜ MLX ì»¤ë®¤ë‹ˆí‹° êµ¬í˜„</a></li>
<li>July 4, 2025. <a href="https://github.com/ml-explore/mlx">MLX</a> support in progress. To preview or contribute, please check out this PR started by @Goekdeniz-Guelmez:
2025ë…„ 7ì›” 4ì¼. <a href="https://github.com/ml-explore/mlx">MLX</a> ì§€ì›ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ë¯¸ë¦¬ ë³´ê±°ë‚˜ ê¸°ì—¬í•˜ë ¤ë©´ @Goekdeniz-Guelmezê°€ ì‹œì‘í•œ PRì„ í™•ì¸í•˜ì„¸ìš”.<a href="https://github.com/ml-explore/mlx-lm/pull/270">this PR</a></li>
<li>July 4, 2025. Update inference usage/examples/demo.
2025ë…„ 7ì›” 4ì¼. ì¶”ë¡  ì‚¬ìš©/ì˜ˆì œ/ë°ëª¨ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.</li>
<li>July 2, 2025. Models are available on Huggingface.
2025ë…„ 7ì›” 2ì¼. ëª¨ë¸ì€ Huggingfaceì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
<li>July 1, 2025. Code is available.
2025ë…„ 7ì›” 1ì¼. ì½”ë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
</ul>
<p><img src="https://github.com/apple/ml-diffucoder/raw/main/figs/teaser.png" alt=""></p>
<h3 id="motivation-ë™ê¸°">Motivation ë™ê¸°</h3>
<p>Scaling upon Masked Denoising Models (MDMs), diffusion LLMs (dLLMs) such as <a href="https://ml-gsai.github.io/LLaDA-demo/">LLaDA</a> and <a href="https://hkunlp.github.io/blog/2025/dream/">Dream</a> have achieved performance on par with similarly sized autoregressive (AR) LLMs across many benchmarks. Recent commercial-scale dLLMs like <a href="https://chat.inceptionlabs.ai/">Mercury</a> and <a href="https://deepmind.google/models/gemini-diffusion/">Gemini</a> further demonstrate that diffusion-based code generators can rival top AR code models on programming tasks while offering faster text generation.
ë§ˆìŠ¤í‚¹ ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸(MDM), <a href="https://ml-gsai.github.io/LLaDA-demo/">LLaDA</a> ë° <a href="https://hkunlp.github.io/blog/2025/dream/">Dream</a>ê³¼ ê°™ì€ í™•ì‚° LLM(dLLM)ì— ëŒ€í•œ í™•ì¥ì€ ë§ì€ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìœ ì‚¬í•œ í¬ê¸°ì˜ ìê°€íšŒê·€(AR) LLMê³¼ ë™ë“±í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. <a href="https://chat.inceptionlabs.ai/">Mercury</a> ë° <a href="https://deepmind.google/models/gemini-diffusion/">Gemini</a>ì™€ ê°™ì€ ìµœê·¼ì˜ ìƒìš© ê·œëª¨ dLLMì€ í™•ì‚° ê¸°ë°˜ ì½”ë“œ ìƒì„±ê¸°ê°€ í”„ë¡œê·¸ë˜ë° ì‘ì—…ì—ì„œ ìµœê³ ì˜ AR ì½”ë“œ ëª¨ë¸ê³¼ ê²½ìŸí•˜ëŠ” ë™ì‹œì— ë” ë¹ ë¥¸ í…ìŠ¤íŠ¸ ìƒì„±ì„ ì œê³µí•  ìˆ˜ ìˆìŒì„ ë”ìš± ë³´ì—¬ì¤ë‹ˆë‹¤.</p>
<p>However, the generation pattern and post-training strategies of dLLMs remain under-explored. In this work, we investigate the following questions:
ê·¸ëŸ¬ë‚˜ dLLMì˜ ìƒì„± íŒ¨í„´ê³¼ í›ˆë ¨ í›„ ì „ëµì€ ì•„ì§ ì—°êµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ ì‘ì—…ì—ì„œëŠ” ë‹¤ìŒ ì§ˆë¬¸ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤.</p>
<ul>
<li><strong>How does the generation pattern of dLLMs differ from AR models?</strong>
<strong>dLLMì˜ ìƒì„± íŒ¨í„´ì€ AR ëª¨ë¸ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ê°€ìš”?</strong></li>
<li><strong>What is the difference in modeling different data modalities, such as code vs. math?</strong>
<strong>ì½”ë“œì™€ ìˆ˜í•™ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ë°ì´í„° ì–‘ì‹ì„ ëª¨ë¸ë§í•  ë•Œ ì–´ë–¤ ì°¨ì´ì ì´ ìˆë‚˜ìš”?</strong></li>
<li><strong>How diverse can dLLMs be, and how should post-training be designed?</strong>
<strong>dLLMì€ ì–¼ë§ˆë‚˜ ë‹¤ì–‘í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬í›„ êµìœ¡ì€ ì–´ë–»ê²Œ ì„¤ê³„í•´ì•¼ í•©ë‹ˆê¹Œ?</strong></li>
</ul>
<p><img src="https://github.com/apple/ml-diffucoder/raw/main/figs/pipeline.png" alt=""></p>
<p>We train <strong>DiffuCoder</strong> using the adaptation approach in <a href="https://github.com/HKUNLP/DiffuLLaMA">DiffuLLaMA</a> and introduce a new metric â€” <strong>autoregressiveness score</strong> â€” to quantify the causal pattern during dLLM generation. The key findings are listed below.
<a href="https://github.com/HKUNLP/DiffuLLaMA">DiffuLLaMA</a>ì˜ ì ì‘ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ <strong>DiffuCoder</strong>ë¥¼ í›ˆë ¨í•˜ê³  dLLM ìƒì„± ì¤‘ ì¸ê³¼ íŒ¨í„´ì„ ì •ëŸ‰í™”í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ì§€í‘œì¸ <strong>ìê¸° íšŒê·€ ì ìˆ˜</strong>ë¥¼ ë„ì…í•©ë‹ˆë‹¤. ì£¼ìš” ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>
<h3 id="findings-ê²°ê³¼">Findings ê²°ê³¼</h3>
<ul>
<li>dLLMs still exhibit a left-to-right bias due to the nature of text, but they can also break this strict order in AR models.
dLLMì€ í…ìŠ¤íŠ¸ì˜ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ì—¬ì „íˆ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í¸í–¥ë˜ì§€ë§Œ AR ëª¨ë¸ì—ì„œ ì´ëŸ¬í•œ ì—„ê²©í•œ ìˆœì„œë¥¼ ê¹¨ëœ¨ë¦´ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</li>
<li>After pre-training, we show that code tasks induce less global AR-ness than math.
ì‚¬ì „ í›ˆë ¨ í›„ ì½”ë“œ ì‘ì—…ì´ ìˆ˜í•™ë³´ë‹¤ ê¸€ë¡œë²Œ ARì„±ì„ ëœ ìœ ë„í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.</li>
<li>In dLLMs, changing the sampling temperature not only affects sampled tokens (as in AR models), but also alters the generation order itself.
dLLMì—ì„œ ìƒ˜í”Œë§ ì˜¨ë„ë¥¼ ë³€ê²½í•˜ë©´ ìƒ˜í”Œë§ëœ í† í°(AR ëª¨ë¸ì—ì„œì™€ ê°™ì´ )ì— ì˜í–¥ì„ ë¯¸ì¹  ë¿ë§Œ ì•„ë‹ˆë¼ ìƒì„± ìˆœì„œ ìì²´ë„ ë³€ê²½ë©ë‹ˆë‹¤.</li>
</ul>
<p>For more interesting findings, please refer to our original paper!
ë” í¥ë¯¸ë¡œìš´ ê²°ê³¼ë¥¼ ì›í•˜ì‹œë©´ ì›ë³¸ ë…¼ë¬¸ì„ ì°¸ì¡°í•˜ì„¸ìš”!</p>
<p>We propose <strong>Coupled-GRPO</strong>, a post-training method to improve DiffuCoderâ€™s performance.
DiffuCoderì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì‚¬í›„ í•™ìŠµ ë°©ë²•ì¸ <strong>Coupled-GRPO</strong>ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.</p>
<hr>
<h3 id="coupled-grpo-ê²°í•©-grpo">Coupled-GRPO ê²°í•©-GRPO</h3>
<p>In diffusion LLMs, the per-timestep loss L t typically computes log-probabilities only at masked token positions, which leads to inefficiency and high variance when sampling is limited. To address this, <strong>Coupled-GRPO</strong> introduces a <em>coupled-sampling</em> scheme:
í™•ì‚° LLMì—ì„œ ì‹œê°„ë‹¨ê³„ ì†ì‹¤ L t ì€ ì¼ë°˜ì ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœ í† í° ìœ„ì¹˜ì—ì„œë§Œ ë¡œê·¸ í™•ë¥ ì„ ê³„ì‚°í•˜ë¯€ë¡œ ìƒ˜í”Œë§ì´ ì œí•œë  ë•Œ ë¹„íš¨ìœ¨ì„±ê³¼ ë†’ì€ ë¶„ì‚°ì´ ë°œìƒí•©ë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ <strong>Coupled-GRPO</strong>ëŠ” <em>ê²°í•© ìƒ˜í”Œë§</em> ì²´ê³„ë¥¼ ë„ì…í•©ë‹ˆë‹¤.</p>
<ul>
<li>For each training example, we select Î» pairs of timesteps ( t , t ^ ) such that t + t ^ = T .
ê° í›ˆë ¨ ì˜ˆì œì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ ì‹œê°„ ë‹¨ê³„ ( t , t ) ìŒì„ ì„ íƒí•©ë‹ˆë‹¤ Î» . t + t = T</li>
<li>We apply two complementary token masks â€” each mask hides part of the tokens, and together they cover the entire set of target tokens.
ë‘ ê°œì˜ ë³´ì™„ì ì¸ í† í° ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤ â€” ê° ë§ˆìŠ¤í¬ëŠ” í† í°ì˜ ì¼ë¶€ë¥¼ ìˆ¨ê¸°ê³  í•¨ê»˜ ì „ì²´ ëŒ€ìƒ í† í° ì„¸íŠ¸ë¥¼ ë®ìŠµë‹ˆë‹¤.</li>
<li>As a result, every token is unmasked in exactly one of the two forward passes.
ê²°ê³¼ì ìœ¼ë¡œ ëª¨ë“  í† í°ì€ ë‘ ê°œì˜ ì „ë‹¬ íŒ¨ìŠ¤ ì¤‘ ì •í™•íˆ í•˜ë‚˜ì—ì„œ ë§ˆìŠ¤í‚¹ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</li>
</ul>
<p>This ensures that: ì´ë¥¼ í†µí•´ ë‹¤ìŒì„ ë³´ì¥í•©ë‹ˆë‹¤.</p>
<ol>
<li>Every tokenâ€™s log-probability is computed at least once, providing a non-zero learning signal for all tokens.
ëª¨ë“  í† í°ì˜ ë¡œê·¸ í™•ë¥ ì€ ì ì–´ë„ í•œ ë²ˆ ê³„ì‚°ë˜ì–´ ëª¨ë“  í† í°ì— ëŒ€í•´ 0ì´ ì•„ë‹Œ í•™ìŠµ ì‹ í˜¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</li>
<li>The probability estimates are more accurate, since each token is evaluated in a realistic partially-masked context (rather than always being fully masked).
í™•ë¥  ì¶”ì •ì¹˜ëŠ” ê° í† í°ì´ í•­ìƒ ì™„ì „íˆ ë§ˆìŠ¤í‚¹ë˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë¶€ë¶„ì ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœ í˜„ì‹¤ì ì¸ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‰ê°€ë˜ê¸° ë•Œë¬¸ì— ë” ì •í™•í•©ë‹ˆë‹¤.</li>
<li>The scheme effectively uses 2 Î» times more sampling passes than the baseline (we choose Î» = 1 ), improving estimation with modest computational overhead.
ì´ ì²´ê³„ëŠ” ê¸°ì¤€ì„ (ìš°ë¦¬ê°€ ì„ íƒ) Î» = 1 ë³´ë‹¤ ëª‡ ë°° ë” ë§ì€ ìƒ˜í”Œë§ íŒ¨ìŠ¤ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ 2 Î» ì ë‹¹í•œ ê³„ì‚° ì˜¤ë²„í—¤ë“œë¡œ ì¶”ì •ì„ ê°œì„ í•©ë‹ˆë‹¤.</li>
</ol>
<p>In this repository, we release our implementation of <strong>Coupled-GRPO</strong>, built upon <a href="https://github.com/huggingface/open-r1/blob/6a0cd5c8ad031fc75118a4ce7f42a4860c3d8dea/">open-r1</a>.
ì´ ì €ì¥ì†Œì—ì„œëŠ” <a href="https://github.com/huggingface/open-r1/blob/6a0cd5c8ad031fc75118a4ce7f42a4860c3d8dea/">open-r1</a>ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ <strong>Coupled-GRPO</strong>ì˜ êµ¬í˜„ì„ ë¦´ë¦¬ìŠ¤í•©ë‹ˆë‹¤.</p>
<h3 id="getting-started-ì‹œì‘">Getting Started ì‹œì‘</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>â”œâ”€â”€ run.sh # start training</span></span>
<span class="line"><span>â”œâ”€â”€ setup.py # modified open-r1/setup.py</span></span>
<span class="line"><span>â”œâ”€â”€ src/open_r1/ #  our code based on open-r1</span></span>
<span class="line"><span>â”‚   â”œâ”€â”€ configs.py # with diffusion related params</span></span>
<span class="line"><span>â”‚   â”œâ”€â”€ coupled_grpo.py # inherits trl GRPOTrainer </span></span>
<span class="line"><span>â”‚   â”œâ”€â”€ grpo.py # main training script</span></span>
<span class="line"><span>â”‚   â”œâ”€â”€ rewards.py # rewrite code reward and code_format reward </span></span>
<span class="line"><span>â”‚   â”œâ”€â”€ utils/code_providers.py # rewrite pass rate extraction for E2B</span></span>
<span class="line"><span>â”œâ”€â”€ recipes/process_data.py # prepare grpo training data</span></span>
<span class="line"><span>â”œâ”€â”€ recipes/config_coupled_code.yaml # training config</span></span>
<span class="line"><span>â”œâ”€â”€ tests/test_code_reward.py # test sandbox execution for code</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="1-prepare-code-and-environment">1. Prepare code and environment</h3>
<ol>
<li>ì½”ë“œ ë° í™˜ê²½ ì¤€ë¹„</li>
</ol>
<p>Clone the source code of Open-R1 from <code>git clone https://github.com/huggingface/open-r1</code>. Merge and replace files between ours and Open-R1â€™s (including <code>setup.py</code>).
ì—ì„œ Open-R1ì˜ ì†ŒìŠ¤ ì½”ë“œë¥¼ ë³µì œí•©ë‹ˆë‹¤ <code>git clone https://github.com/huggingface/open-r1</code> . ë‹¹ì‚¬ì™€ Open-R1(<code>setup.py</code> í¬í•¨) ê°„ì˜ íŒŒì¼ì„ ë³‘í•©í•˜ê³  êµì²´í•©ë‹ˆë‹¤.</p>
<p>Set up the environment and dependencies following Open-R1:
Open-R1 ë‹¤ìŒì— í™˜ê²½ ë° ì¢…ì†ì„±ì„ ì„¤ì •í•©ë‹ˆë‹¤.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>env=openr1</span></span>
<span class="line"><span>conda create -n $env python=3.11 -y -c anaconda</span></span>
<span class="line"><span>conda activate $env</span></span>
<span class="line"><span>pip install vllm==0.8.4</span></span>
<span class="line"><span>pip install setuptools</span></span>
<span class="line"><span>pip install flash-attn==2.8.0.post1 --no-build-isolation</span></span>
<span class="line"><span>pip install -e ".[code]"</span></span>
<span class="line"><span></span></span></code></pre>
<p>Prepare a code sandbox at <a href="https://e2b.dev/">E2B</a>. Export your E2B token to <code>E2B_API_KEY</code> environment variable. Log in to wandb and export your <code>WANDB_ENTITY</code>.
<a href="https://e2b.dev/">E2B</a>ì—ì„œ ì½”ë“œ ìƒŒë“œë°•ìŠ¤ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. E2B í† í°ì„ <code>E2B_API_KEY</code> í™˜ê²½ ë³€ìˆ˜ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤. wandbì— ë¡œê·¸ì¸í•˜ê³  <code>WANDB_ENTITY</code> ë‚´ë³´ëƒ…ë‹ˆë‹¤.</p>
<h3 id="2-data-preparation-2-ë°ì´í„°-ì¤€ë¹„">2. Data preparation 2. ë°ì´í„° ì¤€ë¹„</h3>
<p>We prepare a hard split of GRPO training data based on <a href="https://huggingface.co/datasets/TIGER-Lab/AceCode-87K">AceCode-89k</a>.
<a href="https://huggingface.co/datasets/TIGER-Lab/AceCode-87K">AceCode-89k</a>ë¥¼ ê¸°ë°˜ìœ¼ë¡œ GRPO í›ˆë ¨ ë°ì´í„°ì˜ í•˜ë“œ ë¶„í• ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>cd recipes</span></span>
<span class="line"><span>python process_data.py --dataset_path "TIGER-Lab/AceCode-89K" --output_path "./acecode_hard.jsonl" --difficulty "hard"</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="3-start-grpo-training-3-grpo-êµìœ¡-ì‹œì‘">3. Start GRPO training 3. GRPO êµìœ¡ ì‹œì‘</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>cd ..</span></span>
<span class="line"><span>bash run.sh </span></span>
<span class="line"><span># in `run.sh`, we start e2b server locally, but you can also run it on CPU clusters.</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="inference-ì¶”ë¡ ">Inference ì¶”ë¡ </h3>
<p>The DiffuCoder models (<a href="https://huggingface.co/apple/DiffuCoder-7B-Base">Base</a>, <a href="https://huggingface.co/apple/DiffuCoder-7B-Instruct">Instruct</a>, and <a href="https://huggingface.co/apple/DiffuCoder-7B-cpGRPO">cpGRPO</a>) are now available on HuggingFace. Change <code>TOKEN_PER_STEP</code> to trade off between performance and speed.
ì´ì œ DiffuCoder ëª¨ë¸(<a href="https://huggingface.co/apple/DiffuCoder-7B-Base">Base</a>, <a href="https://huggingface.co/apple/DiffuCoder-7B-Instruct">Instruct</a> ë° <a href="https://huggingface.co/apple/DiffuCoder-7B-cpGRPO">cpGRPO)</a>ì„ HuggingFaceì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ê³¼ ì†ë„ ì‚¬ì´ì—ì„œ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ <code>TOKEN_PER_STEP</code>ë¥¼ ë³€ê²½í•˜ì‹­ì‹œì˜¤.</p>
<p>Usage for Base model (click to expand)
ê¸°ë³¸ ëª¨ë¸ì— ëŒ€í•œ ì‚¬ìš©(í™•ì¥í•˜ë ¤ë©´ í´ë¦­)</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>import torch</span></span>
<span class="line"><span>from transformers import AutoModel, AutoTokenizer</span></span>
<span class="line"><span>model_path = "apple/DiffuCoder-7B-Base"</span></span>
<span class="line"><span>model = AutoModel.from_pretrained(model_path, torch_dtype=torch.bfloat16, trust_remote_code=True)</span></span>
<span class="line"><span>tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)</span></span>
<span class="line"><span>model = model.to("cuda").eval()</span></span>
<span class="line"><span>prompt = """</span></span>
<span class="line"><span>from typing import List</span></span>
<span class="line"><span></span></span>
<span class="line"><span>def has_close_elements(numbers: List[float], threshold: float) -> bool:</span></span>
<span class="line"><span>    \"\"\"</span></span>
<span class="line"><span>    Check if in given list of numbers, are any two numbers closer to each other than given threshold.</span></span>
<span class="line"><span>    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)</span></span>
<span class="line"><span>    False</span></span>
<span class="line"><span>    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)</span></span>
<span class="line"><span>    True</span></span>
<span class="line"><span>    \"\"\"</span></span>
<span class="line"><span>"""</span></span>
<span class="line"><span>TOKEN_PER_STEP = 1 # diffusion timesteps * TOKEN_PER_STEP = total new tokens</span></span>
<span class="line"><span>inputs = tokenizer(prompt, return_tensors="pt")</span></span>
<span class="line"><span>input_ids = inputs.input_ids.to(device="cuda")</span></span>
<span class="line"><span>attention_mask = inputs.attention_mask.to(device="cuda")</span></span>
<span class="line"><span>output = model.diffusion_generate(</span></span>
<span class="line"><span>    input_ids,</span></span>
<span class="line"><span>    attention_mask=attention_mask,</span></span>
<span class="line"><span>    max_new_tokens=256,</span></span>
<span class="line"><span>    output_history=True,</span></span>
<span class="line"><span>    return_dict_in_generate=True,</span></span>
<span class="line"><span>    steps=256//TOKEN_PER_STEP,</span></span>
<span class="line"><span>    temperature=0.2,</span></span>
<span class="line"><span>    top_p=0.95,</span></span>
<span class="line"><span>    alg="entropy",</span></span>
<span class="line"><span>    alg_temp=0.,</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span>generations = [</span></span>
<span class="line"><span>    tokenizer.decode(g[len(p) :].tolist())</span></span>
<span class="line"><span>    for p, g in zip(input_ids, output.sequences)</span></span>
<span class="line"><span>]</span></span>
<span class="line"><span>print(generations[0].split(tokenizer.eos_token)[0])</span></span>
<span class="line"><span></span></span></code></pre>
<p>Output (click to expand)
ì¶œë ¥(í™•ì¥í•˜ë ¤ë©´ í´ë¦­)</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>    # Sort the list to make it easier to find close elements</span></span>
<span class="line"><span>    numbers.sort()</span></span>
<span class="line"><span>    # Iterate through the list, checking each adjacent pair</span></span>
<span class="line"><span>    for i in range(len(numbers) - 1):</span></span>
<span class="line"><span>        # If the difference between the current and next element is less than the threshold, return True</span></span>
<span class="line"><span>        if numbers[i + 1] - numbers[i] &#x3C; threshold:</span></span>
<span class="line"><span>            return True</span></span>
<span class="line"><span>    # If no such pair is found, return False</span></span>
<span class="line"><span>    return False </span></span>
<span class="line"><span></span></span></code></pre>
<blockquote>
<p>Given an example input from the HumanEval test, the output of DiffuCoder-Base is a direct completion of the code snippet.
HumanEval í…ŒìŠ¤íŠ¸ì˜ ì˜ˆì œ ì…ë ¥ì´ ì£¼ì–´ì§€ë©´ DiffuCoder-Baseì˜ ì¶œë ¥ì€ ì½”ë“œ ì¡°ê°ì˜ ì§ì ‘ ì™„ì„±ì…ë‹ˆë‹¤.</p>
</blockquote>
<p>Usage for Instruct model (click to expand)
Instruct ëª¨ë¸ ì‚¬ìš©ë²•(í™•ì¥í•˜ë ¤ë©´ í´ë¦­)</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>import torch</span></span>
<span class="line"><span>from transformers import AutoModel, AutoTokenizer</span></span>
<span class="line"><span>model_path = "apple/DiffuCoder-7B-cpGRPO"</span></span>
<span class="line"><span>model = AutoModel.from_pretrained(model_path, torch_dtype=torch.bfloat16, trust_remote_code=True)</span></span>
<span class="line"><span>tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)</span></span>
<span class="line"><span>model = model.to("cuda").eval()</span></span>
<span class="line"><span>query = "Write a function to find the shared elements from the given two lists."</span></span>
<span class="line"><span>prompt = f"""&#x3C;|im_start|>system</span></span>
<span class="line"><span>You are a helpful assistant.&#x3C;|im_end|></span></span>
<span class="line"><span>&#x3C;|im_start|>user</span></span>
<span class="line"><span>{query.strip()}</span></span>
<span class="line"><span>&#x3C;|im_end|></span></span>
<span class="line"><span>&#x3C;|im_start|>assistant</span></span>
<span class="line"><span>""" ## following the template of qwen; you can also use apply_chat_template function</span></span>
<span class="line"><span>TOKEN_PER_STEP = 1 # diffusion timesteps * TOKEN_PER_STEP = total new tokens</span></span>
<span class="line"><span>inputs = tokenizer(prompt, return_tensors="pt")</span></span>
<span class="line"><span>input_ids = inputs.input_ids.to(device="cuda")</span></span>
<span class="line"><span>attention_mask = inputs.attention_mask.to(device="cuda")</span></span>
<span class="line"><span>output = model.diffusion_generate(</span></span>
<span class="line"><span>    input_ids,</span></span>
<span class="line"><span>    attention_mask=attention_mask,</span></span>
<span class="line"><span>    max_new_tokens=256,</span></span>
<span class="line"><span>    output_history=True,</span></span>
<span class="line"><span>    return_dict_in_generate=True,</span></span>
<span class="line"><span>    steps=256//TOKEN_PER_STEP,</span></span>
<span class="line"><span>    temperature=0.4,</span></span>
<span class="line"><span>    top_p=0.95,</span></span>
<span class="line"><span>    alg="entropy",</span></span>
<span class="line"><span>    alg_temp=0.,</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span>generations = [</span></span>
<span class="line"><span>    tokenizer.decode(g[len(p) :].tolist())</span></span>
<span class="line"><span>    for p, g in zip(input_ids, output.sequences)</span></span>
<span class="line"><span>]</span></span>
<span class="line"><span>print(generations[0].split('&#x3C;|dlm_pad|>')[0])</span></span>
<span class="line"><span></span></span></code></pre>
<p>Output (click to expand)
ì¶œë ¥(í™•ì¥í•˜ë ¤ë©´ í´ë¦­)</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Here is the code to solve this problem: </span></span>
<span class="line"><span>```python</span></span>
<span class="line"><span>def shared_elements(list1, list2): </span></span>
<span class="line"><span>  return [value for value in list1 if value in  list2] </span></span>
<span class="line"><span>```&#x3C;|im_end|> </span></span>
<span class="line"><span></span></span></code></pre>
<blockquote>
<p>Given an example input from the MBPP test, the output of DiffuCoder-cpGRPO is a chat-based response.
MBPP í…ŒìŠ¤íŠ¸ì˜ ì˜ˆì œ ì…ë ¥ì´ ì£¼ì–´ì§€ë©´ DiffuCoder-cpGRPOì˜ ì¶œë ¥ì€ ì±„íŒ… ê¸°ë°˜ ì‘ë‹µì…ë‹ˆë‹¤.</p>
</blockquote>
<h3 id="demo-ë°ëª¨">Demo ë°ëª¨</h3>
<p>ğŸš€ Start the demo and enter any prompt you want!
ğŸš€ ë°ëª¨ë¥¼ ì‹œì‘í•˜ê³  ì›í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”!</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>python inference_demo.py</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="evaluation-í‰ê°€">Evaluation í‰ê°€</h3>
<p>The diffusion inference algorithm is based on Dream-7B. The code evaluation is based on <a href="https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval">Qwen2.5-Coder</a>.
í™•ì‚° ì¶”ë¡  ì•Œê³ ë¦¬ì¦˜ì€ Dream-7Bë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ì½”ë“œ í‰ê°€ëŠ” <a href="https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval">Qwen2.5-Coder</a>ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.</p>
<h2 id="acknowledgments-ìŠ¹ì¸ì„">Acknowledgments ìŠ¹ì¸ì„</h2>
<p>We sincerely appreciate the following works for DiffuCoder:
DiffuCoderì— ëŒ€í•œ ë‹¤ìŒ ì‘ì—…ì— ì§„ì‹¬ìœ¼ë¡œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.</p>
<ul>
<li>Our data used in pre-training/mid-training/instruction tuning are from <a href="https://huggingface.co/OpenCoder-LLM">OpenCoder</a>.
ì‚¬ì „ í•™ìŠµ/ì¤‘ê°„ í•™ìŠµ/ëª…ë ¹ì–´ íŠœë‹ì— ì‚¬ìš©ëœ ë°ì´í„°ëŠ” <a href="https://huggingface.co/OpenCoder-LLM">OpenCoder</a>ì—ì„œ ê°€ì ¸ì˜¨ ê²ƒì…ë‹ˆë‹¤.</li>
<li>Our instruction tuning code is based on <a href="https://github.com/hiyouga/LLaMA-Factory">LLaMA-Factory</a>.
ìš°ë¦¬ì˜ ëª…ë ¹ì–´ íŠœë‹ ì½”ë“œëŠ” <a href="https://github.com/hiyouga/LLaMA-Factory">LLaMA-Factory</a>ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.</li>
<li>Our coupled-GRPO is built upon <a href="https://github.com/huggingface/open-r1">Open-R1</a> and <a href="https://github.com/dllm-reasoning/d1">d1</a>.
ë‹¹ì‚¬ì˜ ê²°í•© GRPOëŠ” <a href="https://github.com/huggingface/open-r1">Open-R1</a> ë° <a href="https://github.com/dllm-reasoning/d1">d1</a>ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.</li>
<li>Our evaluation is built upon <a href="https://github.com/HKUNLP/Dream">Dream</a> and <a href="https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval">Qwen2.5-Coder</a>.
ìš°ë¦¬ì˜ í‰ê°€ëŠ” <a href="https://github.com/HKUNLP/Dream">Dream</a>ê³¼ <a href="https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval">Qwen2.5-Coder</a>ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.</li>
</ul>
<h2 id="citation-ì¸ìš©">Citation ì¸ìš©</h2>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>@article{gong2025diffucoder,</span></span>
<span class="line"><span>  title={DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation},</span></span>
<span class="line"><span>  author={Shansan Gong, Ruixiang Zhang, Huangjie Zheng, Jiatao Gu, Navdeep Jaitly, Lingpeng Kong, Yizhe Zhang},</span></span>
<span class="line"><span>  year={2025},</span></span>
<span class="line"><span>  eprint={2506.20639},</span></span>
<span class="line"><span>  archivePrefix={arXiv},</span></span>
<span class="line"><span>  primaryClass={cs.CL},</span></span>
<span class="line"><span>  url={https://arxiv.org/abs/2506.20639},</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span></code></pre> </article> </div> <script type="module">
      // ëª©ì : index.jsonì—ì„œ í˜„ì¬ ê¸€ ë©”íƒ€/ì¸ë„¤ì¼ì„ ì°¾ì•„ ìƒì„¸ í™”ë©´ì— ë°˜ì˜í•œë‹¤.
      async function hydrateMeta() {
        try {
          const BASE = import.meta.env.BASE_URL;
          const slug = decodeURIComponent(location.pathname.replace(/.*\/post\//,'').replace(/\/?$/,''));
          const res = await fetch(`${BASE}index.json`);
          const data = await res.json();
          const items = (data && data.items) || [];
          const item = items.find((i) => i.slug === slug);
          if (!item) return;

          const hero = document.getElementById('hero');
          const heroImg = document.getElementById('heroImg');
          const source = document.getElementById('source');
          const cta = document.getElementById('ctaSource');
          if (item.thumbnail && hero && heroImg) {
            heroImg.setAttribute('src', item.thumbnail);
            hero.style.display = 'block';
          }
          if (item.source_url && source && cta) {
            source.setAttribute('href', item.source_url);
            cta.setAttribute('href', item.source_url);
            source.style.display='inline-block';
            cta.style.display='inline-block';
          }
        } catch {}
      }
      hydrateMeta();

      // ë³µì‚¬ ë²„íŠ¼ ì œê±°ë¨ â€” ìƒë‹¨ì— ì›ë¬¸ ë³´ê¸° ë²„íŠ¼ë§Œ ìœ ì§€
    </script> </body> </html>