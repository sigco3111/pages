<!DOCTYPE html><html lang="ko" data-astro-cid-ztig7rse> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>상세</title><link rel="icon" href="/pages/favicon.svg" type="image/svg+xml"><link rel="icon" href="/pages/favicon-32x32.png" sizes="32x32"><link rel="apple-touch-icon" href="/pages/apple-touch-icon.png" sizes="180x180"><style>:root{color-scheme:light dark}body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}.wrap[data-astro-cid-ztig7rse]{max-width:860px;margin:0 auto;padding:20px}.topbar[data-astro-cid-ztig7rse]{position:sticky;top:0;backdrop-filter:blur(6px);background:color-mix(in oklab,canvas,transparent 35%);border-bottom:1px solid color-mix(in oklab,canvastext,transparent 90%);z-index:10}.topbar[data-astro-cid-ztig7rse] .inner[data-astro-cid-ztig7rse]{display:flex;align-items:center;gap:8px;padding:10px 20px;max-width:860px;margin:0 auto}.btn[data-astro-cid-ztig7rse]{appearance:none;border:1px solid color-mix(in oklab,canvastext,transparent 85%);background:transparent;color:inherit;border-radius:10px;padding:8px 12px;cursor:pointer;font-size:14px}.btn[data-astro-cid-ztig7rse].primary{background:#111827;color:#fff;border-color:#111827}@media (prefers-color-scheme: dark){.btn[data-astro-cid-ztig7rse].primary{background:#e5e7eb;color:#111827;border-color:#e5e7eb}}.hero[data-astro-cid-ztig7rse]{margin:14px 0 8px;display:none}.hero[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{width:100%;height:auto;border-radius:12px;display:block;background:#f3f4f6}article[data-astro-cid-ztig7rse]{line-height:1.72;font-size:16px}article[data-astro-cid-ztig7rse] :is(h1,h2,h3)[data-astro-cid-ztig7rse]{line-height:1.25;margin:24px 0 10px}article[data-astro-cid-ztig7rse] h1[data-astro-cid-ztig7rse]{font-size:28px}article[data-astro-cid-ztig7rse] h2[data-astro-cid-ztig7rse]{font-size:22px}article[data-astro-cid-ztig7rse] h3[data-astro-cid-ztig7rse]{font-size:18px}article[data-astro-cid-ztig7rse] p[data-astro-cid-ztig7rse]{margin:10px 0}article[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{max-width:100%;height:auto;border-radius:8px;background:#f3f4f6}article[data-astro-cid-ztig7rse] pre[data-astro-cid-ztig7rse]{overflow:auto;padding:14px;border:1px solid color-mix(in oklab,canvastext,transparent 90%);border-radius:10px;background:color-mix(in oklab,canvastext,transparent 96%)}article[data-astro-cid-ztig7rse] code[data-astro-cid-ztig7rse]:not(pre code){background:color-mix(in oklab,canvastext,transparent 94%);padding:2px 6px;border-radius:6px}article[data-astro-cid-ztig7rse] blockquote[data-astro-cid-ztig7rse]{border-left:3px solid #9CA3AF;margin:8px 0;padding:4px 12px;color:#6b7280}.actions[data-astro-cid-ztig7rse]{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0 18px}
</style></head> <body class="container" style="padding:24px;max-width:900px" data-astro-cid-ztig7rse> <div class="topbar" data-astro-cid-ztig7rse> <div class="inner" data-astro-cid-ztig7rse> <a class="btn" href="/pages/" aria-label="홈으로" data-astro-cid-ztig7rse>← 홈</a> <a class="btn" id="source" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 보기</a> </div> </div> <div class="wrap" data-astro-cid-ztig7rse> <h1 style="margin:10px 0 6px" data-astro-cid-ztig7rse></h1> <div class="hero" id="hero" data-astro-cid-ztig7rse><img alt="" id="heroImg" loading="eager" data-astro-cid-ztig7rse></div> <div class="actions" data-astro-cid-ztig7rse> <a class="btn primary" id="ctaSource" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 바로가기</a> </div> <article data-astro-cid-ztig7rse> <h1 id="레퍼런스-기반-애니메이션-채색-longanimation">레퍼런스 기반 애니메이션 채색, LongAnimation</h1>
<p>발견일: 2025/07/07
원문 URL: <a href="https://github.com/CN-makers/LongAnimation">https://github.com/CN-makers/LongAnimation</a>
분류: 오픈소스
원문 Source: 🔗github
즐겨찾기: No</p>
<p><a href="https://opengraph.githubassets.com/86cfe0b61cbdf16e0bba9a8f0fe420241a3e3ee6a657e5e2d3978b5e0108e81e/CN-makers/LongAnimation"></a></p>
<h1 id="longanimation-long-animation-generation-with-dynamic-global-local-memory">LongAnimation: Long Animation Generation with Dynamic Global-Local Memory</h1>
<p>LongAnimation: 동적 전역-로컬 메모리를 사용한 긴 애니메이션 생성</p>
<p><a href="https://camo.githubusercontent.com/127d20f716b7227446bc8af440e5a6b695d1f6e87e4c1dd3c33098969a2306ca/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d50726f6a656374266d6573736167653d5765627369746526636f6c6f723d626c7565"></a></p>
<p><a href="https://camo.githubusercontent.com/4721e7c059058929d64409fc70e8c46871098ff44e8d0a4e147c7c5e082cbc81/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d323035372e30313934352d6233316231622e737667"></a></p>
<p><a href="https://camo.githubusercontent.com/41acc901d5ed8336e63cb54e3895314b14b3c136badab81b8a09d580d32e3b09/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170616368652d79656c6c6f77"></a></p>
<p>video.mp4</p>
<blockquote>
<p><a href="https://cn-makers.github.io/long_animation_web/"><strong>LongAnimation: Long Animation Generation with Dynamic Global-Local Memory</strong></a>
<a href="https://cn-makers.github.io/long_animation_web/"><strong>LongAnimation: 동적 전역-로컬 메모리를 사용한 긴 애니메이션 생성</strong></a></p>
</blockquote>
<p><a href="https://openreview.net/profile?id=~Nan_Chen13">Nan Chen</a>1, <a href="https://corleone-huang.github.io/">Mengqi Huang</a>1, <a href="https://yihao-meng.github.io/">Yihao Meng</a>2, <a href="https://faculty.ustc.edu.cn/maozhendong/en/index.htm">Zhendong Mao</a>†,1
<a href="https://openreview.net/profile?id=~Nan_Chen13">난 첸</a>1, <a href="https://corleone-huang.github.io/">멩치 황</a>1, <a href="https://yihao-meng.github.io/">이하오 멩</a>2, <a href="https://faculty.ustc.edu.cn/maozhendong/en/index.htm">젠동 마오</a>†,1
1USTC 2HKUST †corresponding author
1 USTC 2HKUST †교신저자</p>
<blockquote>
<p>Existing studies are limited to short-term colorization by fusing overlapping features to achieve smooth transitions, which fails to maintain long-term color consistency. In this study, we propose a dynamic global-local paradigm to achieve ideal long-term color consistency by dynamically extracting global color-consistent features relevant to the current generation.
기존 연구는 부드러운 전환을 달성하기 위해 겹치는 특징을 융합하여 단기적인 색상화에 국한되어 장기적인 색상 일관성을 유지하지 못합니다. 본 연구에서는 현재 세대와 관련된 글로벌 색상 일관성 특징을 동적으로 추출하여 이상적인 장기 색상 일관성을 달성하기 위한 동적 글로벌-로컬 패러다임을 제안합니다.</p>
</blockquote>
<p>🎉🎉 Our paper, “LongAnimation: Long Animation Generation with Dynamic Global-Local Memory” accepted by ICCV 2025! Looking forward to seeing you at ICCV then! <strong>Strongly recommend seeing our <a href="https://cn-makers.github.io/long_animation_web/">demo page</a>.</strong>
🎉🎉 우리의 논문 “LongAnimation: Long Animation Generation with Dynamic Global-Local Memory”가 ICCV 2025에 승인되었습니다! 그때 ICCV에서 뵙기를 기대합니다! <a href="https://cn-makers.github.io/long_animation_web/">**데모 페이지를</a> 참조하는 것이 좋습니다.**</p>
<h2 id="showcase-쇼케이스">Showcase 쇼케이스</h2>
<p>showcase_1.mp4 showcase_2.mp4 showcase_3.mp4</p>
<h2 id="creative-usage-창의적인-사용">Creative usage 창의적인 사용</h2>
<h3 id="text-guided-background-generation">Text-guided Background Generation</h3>
<p>텍스트 안내 배경 생성</p>
<p>text_1.mp4 text_2.mp4 text_3.mp4</p>
<p><em>A boy and a girl in different environment.</em>
<em>다른 환경에 있는 소년과 소녀.</em></p>
<h2 id="todo-list-all-목록">TODO List ALL 목록</h2>
<ul>
<li>Release the paper and demo page. Visit <a href="https://cn-makers.github.io/long_animation_web/">https://cn-makers.github.io/long_animation_web/</a>
논문 및 데모 페이지를 공개합니다. <a href="https://cn-makers.github.io/long_animation_web/">방문 https://cn-makers.github.io/long_animation_web/</a></li>
<li>Release the code.
코드를 해제합니다.</li>
</ul>
<h2 id="requirements-요구-사항">Requirements 요구 사항</h2>
<p>The training is conducted on 6 A100 GPUs (80GB VRAM), the inference is tested on 1 A100 GPU.
훈련은 6개의 A100 GPU(80GB VRAM)에서 수행되며 추론은 1개의 A100 GPU에서 테스트됩니다.</p>
<h2 id="setup-설치">Setup 설치</h2>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>git clone https://github.com/CN-makers/LongAnimation</span></span>
<span class="line"><span>cd LongAnimation</span></span>
<span class="line"><span></span></span></code></pre>
<h2 id="environment-환경">Environment 환경</h2>
<p>All the tests are conducted in Linux. We suggest running our code in Linux. To set up our environment in Linux, please run:
모든 테스트는 Linux에서 수행됩니다. Linux에서 코드를 실행하는 것이 좋습니다. Linux에서 환경을 설정하려면 다음을 실행하십시오.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>conda create -n LongAnimation python=3.10 -y</span></span>
<span class="line"><span>conda activate LongAnimation</span></span>
<span class="line"><span>bash install.sh</span></span>
<span class="line"><span></span></span></code></pre>
<h2 id="checkpoints-검사점">Checkpoints 검사점</h2>
<ol>
<li>please download the pre-trained CogVideoX-1.5 I2V checkpoints from <a href="https://huggingface.co/THUDM/CogVideoX1.5-5B-I2V">here</a>, and put the whole folder under <code>pretrained_weight</code>, it should look like <code>./pretrained_weights/CogVideoX1.5-5B-I2V</code>
<a href="https://huggingface.co/THUDM/CogVideoX1.5-5B-I2V">여기에서</a> 사전 훈련된 CogVideoX-1.5 I2V 체크포인트를 다운로드하고 전체 폴더를 <code>pretrained_weight</code> 아래에 넣으면 다음과 같습니다. <code>./pretrained_weights/CogVideoX1.5-5B-I2V</code></li>
<li>please download the pre-trained long video understanding model Video-XL checkpoints from <a href="https://huggingface.co/sy1998/Video_XL/tree/main">here</a>, and put the whole folder under <code>pretrained_weight</code>, it should look like <code>./pretrained_weights/videoxl</code>
<a href="https://huggingface.co/sy1998/Video_XL/tree/main">여기에서</a> 사전 훈련된 긴 비디오 이해 모델 Video-XL 체크포인트를 다운로드하고 전체 폴더를 <code>pretrained_weight</code> 아래에 놓으면 <code>./pretrained_weights/videoXL과</code> 같이 표시되어야 합니다.</li>
<li>please download the checkpoint for our SketchDiT and DGLM model from <a href="https://huggingface.co/CNcreator0331/LongAnimation/tree/main">here</a>, and put the whole folder as <code>./pretrained_weights/longanimation</code>.
여기에서 SketchDiT 및 DGLM 모델에 대한 체크포인트를 다운로드하고 전체 폴더를 <code>./pretrained_weights/longanimation</code> .</li>
</ol>
<h2 id="generate-your-animation-애니메이션을-생성하세요">Generate Your Animation! 애니메이션을 생성하세요!</h2>
<p>To colorize the target lineart sequence with a specific character design, you can run the following command:
특정 캐릭터 디자인으로 대상 선화 시퀀스를 색칠하려면 다음 명령을 실행할 수 있습니다.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>bash  long_animation_inference.sh</span></span>
<span class="line"><span></span></span></code></pre>
<p>We provide some test cases in <code>test_json</code> folder. You can also try our model with your own data. You can change the lineart sequence and corresponding character design in the script <code>Long_animation_inference.sh</code>.
폴더에 몇 가지 테스트 사례<code>test_json</code> 제공합니다. 자신의 데이터로 모델을 사용해 볼 수도 있습니다. 스크립트 <code>Long_animation_inference.sh</code>에서 선화 순서와 해당 캐릭터 디자인을 변경할 수 있습니다.</p>
<p>During the official training, the —height and —weight we used were 576 and 1024 respectively. Additionally, the model can also be compatible with resolutions of 768 in length and 1360 in width respectively.
공식 훈련 기간 동안 우리가 사용한 —height 및 —weight는 각각 576과 1024였습니다. 또한 이 모델은 각각 길이 768, 너비 1360의 해상도와도 호환될 수 있습니다.</p>
<h2 id="citation">Citation:</h2>
<p>Don’t forget to cite this source if it proves useful in your research!</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>@misc{chen2025longanimationlonganimationgeneration,</span></span>
<span class="line"><span>      title={LongAnimation: Long Animation Generation with Dynamic Global-Local Memory}, </span></span>
<span class="line"><span>      author={Nan Chen and Mengqi Huang and Yihao Meng and Zhendong Mao},</span></span>
<span class="line"><span>      year={2025},</span></span>
<span class="line"><span>      eprint={2507.01945},</span></span>
<span class="line"><span>      archivePrefix={arXiv},</span></span>
<span class="line"><span>      primaryClass={cs.CV},</span></span>
<span class="line"><span>      url={https://arxiv.org/abs/2507.01945}, </span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span></code></pre>
<h2 id="star-history">Star History</h2>
<p><a href="https://camo.githubusercontent.com/f6a2989efdd2c8720f169f8390ae37a6b3ca24045d4dd136f55cdebd3e8a0d6c/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d434e2d6d616b6572732f4c6f6e67416e696d6174696f6e26747970653d44617465"></a></p> </article> </div> <script type="module">
      // 목적: index.json에서 현재 글 메타/썸네일을 찾아 상세 화면에 반영한다.
      async function hydrateMeta() {
        try {
          const BASE = import.meta.env.BASE_URL;
          const slug = decodeURIComponent(location.pathname.replace(/.*\/post\//,'').replace(/\/?$/,''));
          const res = await fetch(`${BASE}index.json`);
          const data = await res.json();
          const items = (data && data.items) || [];
          const item = items.find((i) => i.slug === slug);
          if (!item) return;

          const hero = document.getElementById('hero');
          const heroImg = document.getElementById('heroImg');
          const source = document.getElementById('source');
          const cta = document.getElementById('ctaSource');
          if (item.thumbnail && hero && heroImg) {
            heroImg.setAttribute('src', item.thumbnail);
            hero.style.display = 'block';
          }
          if (item.source_url && source && cta) {
            source.setAttribute('href', item.source_url);
            cta.setAttribute('href', item.source_url);
            source.style.display='inline-block';
            cta.style.display='inline-block';
          }
        } catch {}
      }
      hydrateMeta();

      // 복사 버튼 제거됨 — 상단에 원문 보기 버튼만 유지
    </script> </body> </html>