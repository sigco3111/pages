<!DOCTYPE html><html lang="ko" data-astro-cid-ztig7rse> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>상세</title><link rel="icon" href="/pages/favicon.svg" type="image/svg+xml"><link rel="icon" href="/pages/favicon-32x32.png" sizes="32x32"><link rel="apple-touch-icon" href="/pages/apple-touch-icon.png" sizes="180x180"><style>:root{color-scheme:light dark}body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}.wrap[data-astro-cid-ztig7rse]{max-width:860px;margin:0 auto;padding:20px}.topbar[data-astro-cid-ztig7rse]{position:sticky;top:0;backdrop-filter:blur(6px);background:color-mix(in oklab,canvas,transparent 35%);border-bottom:1px solid color-mix(in oklab,canvastext,transparent 90%);z-index:10}.topbar[data-astro-cid-ztig7rse] .inner[data-astro-cid-ztig7rse]{display:flex;align-items:center;gap:8px;padding:10px 20px;max-width:860px;margin:0 auto}.btn[data-astro-cid-ztig7rse]{appearance:none;border:1px solid color-mix(in oklab,canvastext,transparent 85%);background:transparent;color:inherit;border-radius:10px;padding:8px 12px;cursor:pointer;font-size:14px}.btn[data-astro-cid-ztig7rse].primary{background:#111827;color:#fff;border-color:#111827}@media (prefers-color-scheme: dark){.btn[data-astro-cid-ztig7rse].primary{background:#e5e7eb;color:#111827;border-color:#e5e7eb}}.hero[data-astro-cid-ztig7rse]{margin:14px 0 8px;display:none}.hero[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{width:100%;height:auto;border-radius:12px;display:block;background:#f3f4f6}article[data-astro-cid-ztig7rse]{line-height:1.72;font-size:16px}article[data-astro-cid-ztig7rse] :is(h1,h2,h3)[data-astro-cid-ztig7rse]{line-height:1.25;margin:24px 0 10px}article[data-astro-cid-ztig7rse] h1[data-astro-cid-ztig7rse]{font-size:28px}article[data-astro-cid-ztig7rse] h2[data-astro-cid-ztig7rse]{font-size:22px}article[data-astro-cid-ztig7rse] h3[data-astro-cid-ztig7rse]{font-size:18px}article[data-astro-cid-ztig7rse] p[data-astro-cid-ztig7rse]{margin:10px 0}article[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{max-width:100%;height:auto;border-radius:8px;background:#f3f4f6}article[data-astro-cid-ztig7rse] pre[data-astro-cid-ztig7rse]{overflow:auto;padding:14px;border:1px solid color-mix(in oklab,canvastext,transparent 90%);border-radius:10px;background:color-mix(in oklab,canvastext,transparent 96%)}article[data-astro-cid-ztig7rse] code[data-astro-cid-ztig7rse]:not(pre code){background:color-mix(in oklab,canvastext,transparent 94%);padding:2px 6px;border-radius:6px}article[data-astro-cid-ztig7rse] blockquote[data-astro-cid-ztig7rse]{border-left:3px solid #9CA3AF;margin:8px 0;padding:4px 12px;color:#6b7280}.actions[data-astro-cid-ztig7rse]{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0 18px}
</style></head> <body class="container" style="padding:24px;max-width:900px" data-astro-cid-ztig7rse> <div class="topbar" data-astro-cid-ztig7rse> <div class="inner" data-astro-cid-ztig7rse> <a class="btn" href="/pages/" aria-label="홈으로" data-astro-cid-ztig7rse>← 홈</a> <a class="btn" id="source" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 보기</a> </div> </div> <div class="wrap" data-astro-cid-ztig7rse> <h1 style="margin:10px 0 6px" data-astro-cid-ztig7rse></h1> <div class="hero" id="hero" data-astro-cid-ztig7rse><img alt="" id="heroImg" loading="eager" data-astro-cid-ztig7rse></div> <div class="actions" data-astro-cid-ztig7rse> <a class="btn primary" id="ctaSource" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 바로가기</a> </div> <article data-astro-cid-ztig7rse> <h1 id="시각-언어-모델vision-language-model-활용시-꼭-알아야-할-사실">시각 언어 모델(Vision Language Model) 활용시 꼭 알아야 할 사실</h1>
<p>발견일: 2025/07/08
원문 URL: <a href="https://devocean.sk.com/blog/techBoardDetail.do?ID=167591">https://devocean.sk.com/blog/techBoardDetail.do?ID=167591</a>
분류: 인사이트
원문 Source: 🔗devocean.sk
즐겨찾기: No</p>
<p><img src="https://devocean.sk.com/thumnail/2025/7/8/0f8747af1ebbec0805f3444775c98e4715b051d7c2bcad90468caee53f829a31.png" alt=""></p>
<p>안녕하세요.</p>
<p>SK하이닉스에서 OCR 관련 프로젝트를 진행하고 있는 담당자 입니다.</p>
<p>최근에는 거의 모든 생성형 AI 도구들이 멀티 모달을 지원하고 있고, 또 일상 생활에서 자연스럽게 활용하고 있습니다.</p>
<p>(모르는 언어로 된 메뉴판을 번역한다던가, 어떤 사진인지 맞추게 시킨다던가)</p>
<p>활용해보면 굉장히 인식률이 좋고, 자연스럽게 기존 OCR 업무에도 확장해서 사용하는 시도가 많이 보입니다.</p>
<p>실제로 현업에서도 VLM (Vision Language Model)을 활용해서 PPT 내용을 읽어오거나, 반도체 Pattern의 결함을 찾는 시도들을 많이 하고 있습니다.</p>
<p>실제로 OCR 관련 과제를 할때도 OCR 모델과 생성형 AI 모델을 결합해서 프로젝트를 진행하고 있습니다.</p>
<p>그런데, 사실 VLM이 장님이자, 실제 사진을 제대로 보는게 아니라는 충격적인(?) 논문을 보게되어 공유 드리고자 글을 쓰게 되었습니다.</p>
<p>VLM을 활용해서 이미지 인식 과제를 진행하시는 분들께서는 꼭 참고해보시면 도움이 될거라고 생각 됩니다.</p>
<h2 id="1-사실-vlm은-장님이다">1. 사실 VLM은 장님이다?</h2>
<p>여기 매우 쉬운 문제가 있습니다. 빨간선과 파란선이 교점을 몇개 가지고 있는지 맞추는 문제인데요.</p>
<p>Claude의 최신 모델인 Sonnet-4로 물어봤습니다.</p>
<p><a href="https://devocean.sk.com/editorImg/2025/6/29/d9618efb5ddc7588d908efc543403c25637c88241e18fe96f4ef379604be6d36"></a></p>
<p>정답은 0개로 사실 누구나 맞출 수 있는 문제 인데, VLM은 마치 장님 처럼 틀립니다.</p>
<p>위 예시 처럼 논문에서는 유치원생 수준이라면 누구나 맞출 수 있는 “공간 관계” 문제를 주고, VLM 모델들이 얼마나 정답을 잘 맞추는지 테스트 해본 내용이 소개되고 있습니다.</p>
<p>총 7개의 Task가 있고, 모두 사람이라면 손쉽게 맞출 수 있는 문제로 구성되어 있습니다.</p>
<p><a href="https://devocean.sk.com/editorImg/2025/6/29/1455438efdd496b74b85545638519b51cbaa42f10dc2e46cba3090701bd474ec"></a></p>
<ol>
<li>교점의 개수 맞추기</li>
<li>2개의 원이 오버랩 되어있는지 판단하기</li>
<li>글자에 빨간색 동그라미를 치고, 동그라미친 단어 맞추기</li>
<li>원이 몇개 있는지 맞추기</li>
<li>사각형이 몇개 있는지 맞추기</li>
<li>표의 행/열 개수 맞추기</li>
<li>노선도로 갈 수 있는 개수 맞추기</li>
</ol>
<p>전부 쉬운 난이도의 문제지만 아래 벤치마크 결과를 보면 각 Task별 정확도는 상용으로는 전혀 쓰지 못할 수준임을 알 수 있습니다.</p>
<p><a href="https://devocean.sk.com/editorImg/2025/6/29/d137b8158ac4a8a5de4c856ce69f42ffb7bd61bbf25175593adc504d7a8979d9"></a></p>
<p>출처 : <a href="https://vlmsareblind.github.io/">Vision language models are blind</a></p>
<h2 id="2-vlm은-통념을-벗어나지-못한다">2. VLM은 통념을 벗어나지 못한다?</h2>
<p>이 내용도 충격적인데요. 우리가 흔히 통념으로 알고 있는 내용 (개의 다리는 4개, 아디다스 로고는 줄 3개 등)</p>
<p>에서 조금만 (개의 다리를 5개도 바꾼다던가) 내용을 바꾸면 VLM은 틀린 답을 내놓습니다.</p>
<p><a href="https://devocean.sk.com/editorImg/2025/6/29/68a0aa22379265c52aa0bd9e93e6f513dd610ebb4c74968eccd6661926fb95f3"></a></p>
<p>퓨마 그림에 다리 1개만 추가 했을 뿐인데, 우리가 아는 최신 모델이 전부 틀리는걸 확인할 수 있습니다.</p>
<p>아디다스 로고에 줄 1개만 추가해도 통념을 벗어나지 못하고 3개로 답변 하네요.</p>
<p>실제 논문에서는 위와 같이 우리가 알고 있고, LLM도 알고 있는 통념에 살짝만 변주를 주어도 이미지 분석을 수행 못하게 됩니다.</p>
<blockquote>
<p>VLM모델은 실제 시각 분석 결과보다 학습된 기억에 더 의존하고 있음을 알 수 있습니다.</p>
</blockquote>
<p>아래 이미지는 기존 통념에 반하는 내용을 넣고, 각 모델별 질문과 정답을 맞췄는지를 보여줍니다.</p>
<p>(맞추는게 거의 없습니다..)</p>
<p><a href="https://devocean.sk.com/editorImg/2025/6/29/b90caac38b017606bc779fa4db03f3cd949619788347b866a73ee7ad401ea38f"></a></p>
<p>출처 : <a href="https://vlmsarebiased.github.io/">Vision Language Models are Biased</a></p>
<h2 id="3-결론">3. 결론</h2>
<p>우리가 VLM을 활용하면서 지금까지 생기는 오류들을 기존에는 1) 랜덤 에러 2) 모델 성능 3) 낮은 화질 등으로 생각했지만 실제 VLM은 명확한 구멍이 있으며,</p>
<p>실제 현업에 적용하기 전에 위험성(?)에 대해 고민해봐야 할 것 같습니다.</p>
<p>특히 반도체 Pattern 같은 자연적인 이미지가 아닌 도형의 공간 정보를 해석함에 취약점을 가지고 있고, 아주 조금의 변경으로도 결과가 완전히 뒤바뀔 수 있습니다.</p>
<p>간단하게 VLM의 한계에 관련한 2편의 논문을 살펴보았는데요. 혹시 이미지 인식 관련 과제에 VLM을 활용하시려는 분들께서는 참고가 많이 될 것 같습니다.</p> </article> </div> <script type="module">
      // 목적: index.json에서 현재 글 메타/썸네일을 찾아 상세 화면에 반영한다.
      async function hydrateMeta() {
        try {
          const BASE = import.meta.env.BASE_URL;
          const slug = decodeURIComponent(location.pathname.replace(/.*\/post\//,'').replace(/\/?$/,''));
          const res = await fetch(`${BASE}index.json`);
          const data = await res.json();
          const items = (data && data.items) || [];
          const item = items.find((i) => i.slug === slug);
          if (!item) return;

          const hero = document.getElementById('hero');
          const heroImg = document.getElementById('heroImg');
          const source = document.getElementById('source');
          const cta = document.getElementById('ctaSource');
          if (item.thumbnail && hero && heroImg) {
            heroImg.setAttribute('src', item.thumbnail);
            hero.style.display = 'block';
          }
          if (item.source_url && source && cta) {
            source.setAttribute('href', item.source_url);
            cta.setAttribute('href', item.source_url);
            source.style.display='inline-block';
            cta.style.display='inline-block';
          }
        } catch {}
      }
      hydrateMeta();

      // 복사 버튼 제거됨 — 상단에 원문 보기 버튼만 유지
    </script> </body> </html>