<!DOCTYPE html><html lang="ko" data-astro-cid-ztig7rse> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>상세</title><link rel="icon" href="/pages/favicon.svg" type="image/svg+xml"><link rel="icon" href="/pages/favicon-32x32.png" sizes="32x32"><link rel="apple-touch-icon" href="/pages/apple-touch-icon.png" sizes="180x180"><style>:root{color-scheme:light dark}body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}.wrap[data-astro-cid-ztig7rse]{max-width:860px;margin:0 auto;padding:20px}.topbar[data-astro-cid-ztig7rse]{position:sticky;top:0;backdrop-filter:blur(6px);background:color-mix(in oklab,canvas,transparent 35%);border-bottom:1px solid color-mix(in oklab,canvastext,transparent 90%);z-index:10}.topbar[data-astro-cid-ztig7rse] .inner[data-astro-cid-ztig7rse]{display:flex;align-items:center;gap:8px;padding:10px 20px;max-width:860px;margin:0 auto}.btn[data-astro-cid-ztig7rse]{appearance:none;border:1px solid color-mix(in oklab,canvastext,transparent 85%);background:transparent;color:inherit;border-radius:10px;padding:8px 12px;cursor:pointer;font-size:14px}.btn[data-astro-cid-ztig7rse].primary{background:#111827;color:#fff;border-color:#111827}@media (prefers-color-scheme: dark){.btn[data-astro-cid-ztig7rse].primary{background:#e5e7eb;color:#111827;border-color:#e5e7eb}}.hero[data-astro-cid-ztig7rse]{margin:14px 0 8px;display:none}.hero[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{width:100%;height:auto;border-radius:12px;display:block;background:#f3f4f6}article[data-astro-cid-ztig7rse]{line-height:1.72;font-size:16px}article[data-astro-cid-ztig7rse] :is(h1,h2,h3)[data-astro-cid-ztig7rse]{line-height:1.25;margin:24px 0 10px}article[data-astro-cid-ztig7rse] h1[data-astro-cid-ztig7rse]{font-size:28px}article[data-astro-cid-ztig7rse] h2[data-astro-cid-ztig7rse]{font-size:22px}article[data-astro-cid-ztig7rse] h3[data-astro-cid-ztig7rse]{font-size:18px}article[data-astro-cid-ztig7rse] p[data-astro-cid-ztig7rse]{margin:10px 0}article[data-astro-cid-ztig7rse] img[data-astro-cid-ztig7rse]{max-width:100%;height:auto;border-radius:8px;background:#f3f4f6}article[data-astro-cid-ztig7rse] pre[data-astro-cid-ztig7rse]{overflow:auto;padding:14px;border:1px solid color-mix(in oklab,canvastext,transparent 90%);border-radius:10px;background:color-mix(in oklab,canvastext,transparent 96%)}article[data-astro-cid-ztig7rse] code[data-astro-cid-ztig7rse]:not(pre code){background:color-mix(in oklab,canvastext,transparent 94%);padding:2px 6px;border-radius:6px}article[data-astro-cid-ztig7rse] blockquote[data-astro-cid-ztig7rse]{border-left:3px solid #9CA3AF;margin:8px 0;padding:4px 12px;color:#6b7280}.actions[data-astro-cid-ztig7rse]{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0 18px}
</style></head> <body class="container" style="padding:24px;max-width:900px" data-astro-cid-ztig7rse> <div class="topbar" data-astro-cid-ztig7rse> <div class="inner" data-astro-cid-ztig7rse> <a class="btn" href="/pages/" aria-label="홈으로" data-astro-cid-ztig7rse>← 홈</a> <a class="btn" id="source" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 보기</a> </div> </div> <div class="wrap" data-astro-cid-ztig7rse> <h1 style="margin:10px 0 6px" data-astro-cid-ztig7rse></h1> <div class="hero" id="hero" data-astro-cid-ztig7rse><img alt="" id="heroImg" loading="eager" data-astro-cid-ztig7rse></div> <div class="actions" data-astro-cid-ztig7rse> <a class="btn primary" id="ctaSource" href="#" target="_blank" rel="noopener" style="display:none" data-astro-cid-ztig7rse>원문 바로가기</a> </div> <article data-astro-cid-ztig7rse> <h1 id="24시간-만에-10억-웹페이지를-크롤링한-2025년형-대규모-크롤러">24시간 만에 10억 웹페이지를 크롤링한 2025년형 대규모 크롤러</h1>
<p>발견일: 2025/07/24
원문 URL: <a href="https://andrewkchan.dev/posts/crawler.html">https://andrewkchan.dev/posts/crawler.html</a>
분류: 인사이트
원문 Source: 🔗andrewkchan
즐겨찾기: No</p>
<h3 id="contents-목차">Contents 목차</h3>
<ul>
<li><a href="https://andrewkchan.dev/posts/crawler.html#">(Top) (위)</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-1">Problem statement 문제 설명</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-2">High-level design 높은 수준의 디자인</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-2.1">Alternatives investigated</a> <a href="https://andrewkchan.dev/posts/crawler.html#section-2.1">조사된 대안</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-3">Learnings 학습</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-3.1">Parsing is a big bottleneck</a> <a href="https://andrewkchan.dev/posts/crawler.html#section-3.1">구문 분석은 큰 병목 현상입니다.</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-3.2">Fetching: both easier and harder</a> <a href="https://andrewkchan.dev/posts/crawler.html#section-3.2">가져오기: 더 쉽고 더 어렵습니다.</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-3.3">The big crawl</a> <a href="https://andrewkchan.dev/posts/crawler.html#section-3.3">큰 크롤링</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-4">Discussion 토론</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-4.1">Theory vs. Practice</a> <a href="https://andrewkchan.dev/posts/crawler.html#section-4.1">이론 대 실습</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#section-4.2">What now?</a> <a href="https://andrewkchan.dev/posts/crawler.html#section-4.2">이번엔 또 뭐예요?</a></li>
<li><a href="https://andrewkchan.dev/posts/crawler.html#bottom">(Comments) (댓글)</a></li>
<li><em>Discussion on <a href="https://www.reddit.com/r/programming/comments/1m1hvh3/crawling_a_billion_web_pages_in_just_over_24/">r/programming</a>.</em>
<a href="https://www.reddit.com/r/programming/comments/1m1hvh3/crawling_a_billion_web_pages_in_just_over_24/">*r/프로그래밍</a>에 대한 토론.*</li>
</ul>
<p>For some reason, nobody’s written about what it takes to crawl a big chunk of the web in a while: the last point of reference I saw was Michael Nielsen’s post from 2012[1].
어떤 이유에서인지 한동안 웹의 큰 덩어리를 크롤링하는 데 필요한 것에 대해 아무도 쓰지 않았습니다: 내가 마지막으로 본 참조 지점은 2012년 마이클 닐슨의 게시물이었습니다[1].</p>
<p>Obviously lots of things have changed since then. Most bigger, better, faster: CPUs have gotten a lot more cores, spinning disks have been replaced by NVMe solid state drives with near-RAM I/O bandwidth, network pipe widths have exploded, EC2 has gone from a tasting menu of instance types to a whole rolodex’s worth, yada yada. But some harder: much more of the web is dynamic, with heavier content too. How has the state of the art changed? Have the bottlenecks shifted, and would it still cost <a href="https://news.ycombinator.com/item?id=17461384">~$41k to bootstrap your own Google</a>? I wanted to find out, so I built and ran my own web crawler1 under similar constraints.
분명히 그 이후로 많은 것들이 바뀌었습니다. 가장 크고, 더 좋고, 더 빠름: CPU는 훨씬 더 많은 코어를 얻었고, 회전하는 디스크는 RAM에 가까운 I/O 대역폭을 가진 NVMe 솔리드 스테이트 드라이브로 대체되었으며, 네트워크 파이프 너비는 폭발적으로 증가했으며, EC2는 인스턴스 유형의 시식 메뉴에서 전체 롤로덱스의 가치로 바뀌었습니다. 그러나 더 어려운 점은 훨씬 더 많은 웹이 역동적이며 콘텐츠도 더 무거워진다는 것입니다. 최첨단 기술은 어떻게 변했습니까? 병목 현상이 바뀌었고 <a href="https://news.ycombinator.com/item?id=17461384">자신의 Google을 부트스트랩하는 데 여전히 ~$41k</a>의 비용이 들까요? 알고 싶어서 비슷한 제약 조건에서 나만의 웹 크롤러1을 구축하고 실행했습니다.</p>
<h1 id="problem-statement-문제-설명">Problem statement 문제 설명</h1>
<p><strong>Time limit of 24 hours</strong>. Because I thought a billion pages crawled in a day was achievable based on preliminary experiments and 40 hours doesn’t sound as cool. In my final crawl, the average active time of each machine was 25.5 hours with a tiny bit of variance. This doesn’t include a few hours for some machines that had to be restarted.
시간 <strong>제한은 24시간</strong>입니다. 예비 실험을 기반으로 하루에 10억 페이지를 크롤링하는 것이 달성 가능하다고 생각했기 때문에 40시간은 그다지 멋지지 않게 들립니다. 마지막 크롤링에서 각 기계의 평균 활성 시간은 25.5시간이었고 약간의 차이가 있었습니다. 여기에는 다시 시작해야 하는 일부 시스템의 경우 몇 시간이 포함되지 않습니다.</p>
<p><strong>Budget of a few hundred dollars</strong>. Nielsen’s crawl cost a bit under $580. I’m lucky enough to have some disposable income saved up, and aimed for my final crawl to fit in the same. The final run including only the 25.5 active hours cost about $462. I also ran a bunch of small-scale experiments while optimizing the single-node system (which cost much less) and a second large-scale experiment to see how far I could take vertical scaling (which I cut off early, but was in the same ballpark).
수<strong>백 달러의 예산</strong>. 닐슨의 크롤링 비용은 580달러 미만이었습니다. 나는 운이 좋게도 가처분 소득을 저축할 수 있었고 마지막 크롤링이 같은 곳에 맞는 것을 목표로 했습니다. 이 25.5시간의 활성 시간만 포함한 최종 실행 비용은 약 $462입니다. 또한 단일 노드 시스템(비용이 훨씬 적음)과 두 번째 시스템을 최적화하면서 소규모 실험을 많이 실행했습니다 수직 스케일링을 얼마나 멀리 할 수 있는지 알아보기 위한 대규모 실험(일찍 차단했지만 같은 야구장에 있었습니다).</p>
<p><strong>HTML only</strong>. The elephant in the room. <a href="https://web.archive.org/web/20170607105910/https://sonniesedge.co.uk/blog/a-day-without-javascript">Even by 2017</a> much of the web had come to require JavaScript. But I wanted an apples-to-apples comparison with older web crawls, and in any case, I was doing this as a side project and didn’t have time to add and optimize a bunch of playwright workers. So I did things the old fashioned way: request all links, but don’t run any JS - just parse the HTML as-is and add all links from <code>&#x3C;a></code> tags to the frontier. I was also curious how much of the web can still be crawled this way; as it turns out a lot!
<strong>HTML만 해당</strong>됩니다. 방 안의 코끼리. <a href="https://web.archive.org/web/20170607105910/https://sonniesedge.co.uk/blog/a-day-without-javascript">2017년에도</a> 많은 웹이 JavaScript를 요구하게 되었습니다. 하지만 저는 이전 웹 크롤링과 사과 대 사과를 비교하고 싶었고, 어쨌든 이 작업을 사이드 프로젝트로 수행하고 있었고 많은 극작가 작업자를 추가하고 최적화할 시간이 없었습니다. 그래서 나는 구식 방식으로 일을 했습니다 : 모든 링크를 요청하되 JS를 실행하지 마십시오 - HTML을 있는 그대로 구문 분석하고 <code>&#x3C;a></code> 태그의 모든 링크를 프론티어에 추가합니다. 나는 또한 얼마나 많은 웹이 여전히 이런 식으로 크롤링될 수 있는지 궁금했습니다. 많은 것으로 밝혀졌습니다!</p>
<p><strong>Politeness</strong>. This is super important! I’ve read a couple stories (<a href="https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html">example</a>) about how much pain is caused to admins by massive web crawls that don’t respect robots.txt, spoof other agents to evade blocks, and relentlessly hammer endpoints. I followed prior art: I adhered to robots.txt, added an informative user agent containing my contact information, maintained a list of excluded domains which I would add to on request, stuck to my seed list of the top 1 million domains to avoid hitting mom-and-pop sites, and enforced a 70 second minimum delay between hitting the same domain.
<strong>공손함</strong>. 이것은 매우 중요합니다! 나는 얼마나 많은 것에 대한 몇 가지 이야기(<a href="https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html">예</a>)를 읽었습니다. robots.txt 존중하지 않는 대규모 웹 크롤링, 차단을 회피하기 위해 다른 에이전트를 스푸핑하고 엔드포인트를 가차없이 망치질하는 대규모 웹 크롤링으로 인해 관리자에게 고통이 발생합니다. 종래 기술을 따랐다: 고수했다 robots.txt 위해 내 연락처 정보가 포함된 유익한 사용자 에이전트를 추가하고, 요청 시 추가할 제외된 도메인 목록을 유지하고, 상위 100만 개의 시드 목록에 붙였습니다. 도메인을 사용하여 소규모 사이트에 도달하지 않도록 하고 동일한 도메인에 도달하는 사이에 최소 70초의 지연을 적용했습니다.</p>
<p><strong>Fault-tolerance</strong>. This was important in case I needed to stop and resume the crawl for whatever reason (which I did). It also helped a lot for experiments because in my one-time crawl procedure, the performance characteristics were state-dependent: the beginning of the crawl looked pretty different than steady-state. I didn’t aim for perfect fault tolerance; losing some visited sites in the recovery after a crash or failure was fine, because my crawl was fundamentally a sample of the web.
<strong>내결함성</strong>. 이것은 어떤 이유로든 크롤링을 중지하고 재개해야 하는 경우에 중요했습니다. 또한 일회성 크롤링에서 실험에 많은 도움이 되었습니다. 절차에서 성능 특성은 상태에 따라 달라졌습니다: 크롤링의 시작은 정상 상태와 상당히 다르게 보였습니다. 나는 완벽한 내결함성을 목표로 하지 않았습니다. 일부 손실 충돌 또는 실패 후 복구 시 방문한 사이트는 기본적으로 웹의 샘플이었기 때문에 괜찮았습니다.</p>
<h1 id="high-level-design-높은-수준의-디자인">High-level design 높은 수준의 디자인</h1>
<p>The design I ended up with looked pretty different than the typical crawler solution for systems design interviews, which generally disaggregates the functions (parsing, fetching, datastore, crawl state) into totally separate machine pools. What I went with instead was a cluster of a dozen highly-optimized independent nodes, each of which contained all the crawler functionality and handled a shard of domains. I did this because:
내가 끝낸 디자인은 일반적으로 기능(구문 분석, 가져오기, 데이터 저장소, 크롤링 상태)을 완전히 별도의 머신 풀로 분해하는 시스템 설계 인터뷰를 위한 일반적인 크롤러 솔루션과 상당히 달라 보였습니다. 대신 제가 선택한 것은 고도로 최적화된 12개의 독립 노드로 구성된 클러스터였으며, 각 노드에는 모든 크롤러 기능이 포함되어 있고 도메인 샤드를 처리했습니다. 나는 다음과 같은 이유로 이것을 했습니다.</p>
<ul>
<li>I was operating under a limited budget for both experiments and the final run, so it made sense for me to start small, pack as much as possible onto a single machine, and then scale that up.
실험과 최종 실행 모두에 대해 제한된 예산으로 운영하고 있었기 때문에 작게 시작하여 가능한 한 많은 것을 단일 기계에 담은 다음 확장하는 것이 합리적이었습니다.</li>
<li>I’d actually started with the goal of maximizing performance of a single machine rather than the goal above of a billion pages in 24 hours (which I added halfway through). Even after adding that goal, I was still really optimistic about vertical scaling, and only gave up and moved to a cluster design when I started to approach my self-imposed deadline.
나는 실제로 24시간 안에 10억 페이지라는 목표보다는 단일 컴퓨터의 성능을 극대화하는 목표로 시작했습니다(중간에 추가했습니다). 그 목표를 추가한 후에도 저는 여전히 수직 확장에 대해 정말 낙관적이었고, 스스로 정한 마감일이 다가오기 시작했을 때에야 포기하고 클러스터 디자인으로 전환했습니다.</li>
</ul>
<p><img src="https://andrewkchan.dev/posts/crawler-assets/crawler-design.png" alt=""></p>
<p>In detail, each node consisted of the following:
세부적으로 각 노드는 다음으로 구성됩니다.</p>
<ul>
<li><strong>A single redis instance</strong> storing data structures representing the crawl state:
크롤링 상태를 나타내는 데이터 구조를 저장하는 <strong>단일 redis 인스턴스</strong>:
<ul>
<li><strong>Per-domain frontiers</strong>, or lists of URLs to crawl
<strong>도메인별 프론티어</strong> 또는 크롤링할 URL 목록</li>
<li><strong>Queue of domains</strong> ordered by the next timestamp at which they could be fetched based on their crawl delay2
크롤링 지연을 기반으로 가져올 수 있는 다음 타임스탬프별로 정렬된 <strong>도메인 큐</strong> 2</li>
<li><strong>Entries for all visited URLs</strong>, with each URL associated with some metadata and path to the saved content3 on disk
<strong>방문한 모든 URL에 대한 항목</strong>, 각 URL은 일부 메타데이터와 연결된 항목 및 디스크에 저장된 콘텐츠3의 경로</li>
<li><strong>Seen URLs bloom filter</strong> so that we could quickly determine whether a URL had been added the frontier already. This was separate from the visited entries because we didn’t want to add a URL to a frontier if it was already there, but not yet fetched. The small probability of the bloom filter giving false positives4 was fine because again, I’d decided my crawl was a sample of the internet, and I was optimizing for speed.
<strong>본 URL 블룸 필터</strong>를 사용하면 URL이 이미 프론티어에 추가되었는지 여부를 빠르게 확인할 수 있습니다. 이것은 이미 존재하지만 아직 가져오지 않은 경우 프론티어에 URL을 추가하고 싶지 않았기 때문에 방문한 항목과 별개였습니다. 블룸 필터가 오탐4를 줄 확률은 적었는데, 다시 말하지만, 내 크롤링이 인터넷의 샘플이라고 결정하고 속도를 최적화하고 있었기 때문에 괜찮았습니다.</li>
<li><strong>Domain metadata</strong>, including whether a domain was manually excluded, part of the original seed list, and the full content of its robots.txt (+ robots expiration timestamp).
도메인이 수동으로 제외되었는지 여부, 원래 시드 목록의 일부, robots.txt의 전체 콘텐츠(+ 로봇 만료 타임스탬프)를 포함한 <strong>도메인 메타데이터</strong>입니다.</li>
<li><strong>Parse queue</strong> containing the fetched HTML pages for the parsers to process.
구문 분석기가 처리할 가져오기 HTML 페이지가 포함된 <strong>대기열</strong>입니다.</li>
</ul>
</li>
<li><strong>Pool of fetcher processes:</strong>
<strong>페처 프로세스 풀:</strong>
<ul>
<li>Fetchers operated in a simple loop: pop the next ready domain from redis, then pop the next URL from its frontier and fetch it (+ replace the domain in the ready queue), then push the result onto the parse queue.
간단한 루프에서 작동하는 페처는 redis에서 다음 준비 도메인을 팝한 다음 프론티어에서 다음 URL을 팝하여 가져온 다음 (+ 준비 대기열의 도메인 교체) 결과를 구문 분석 대기열에 푸시합니다.</li>
<li>Each process packed high concurrency onto a single core via asyncio; I empirically found fetchers could support 6000-7000 “workers” (independent asynchronous fetch loop). Note this didn’t come close to saturating network bandwidth: the bottleneck was the CPU, which I’ll go into later. The async design is a form of user-space multitasking and has been popular for a while for high concurrency systems (<a href="https://en.wikipedia.org/wiki/Tornado_(web_server)">Python Tornado</a> came out in 2009!) because it avoids context switching entirely.
각 프로세스는 asyncio를 통해 단일 코어에 높은 동시성을 포장했습니다. 경험적으로 페처가 6000-7000 개의 “작업자”(독립적 인 비동기 페치 루프)를 지원할 수 있음을 발견했습니다. 이것은 네트워크 대역폭을 포화시키는 데 근접하지 않았습니다: 병목 현상은 나중에 설명할 CPU였습니다. 비동기 디자인은 사용자 공간 멀티태스킹의 한 형태이며 컨텍스트 전환을 완전히 피하기 때문에 동시성이 높은 시스템(<a href="https://en.wikipedia.org/wiki/Tornado_(web_server)">Python Tornado</a>는 2009년에 출시되었습니다!)에서 한동안 인기를 끌었습니다.</li>
<li>Both fetchers and parsers also maintained LRU caches of important domain data such as robots.txt content so as to minimize load on redis.
또한 페처와 파서 모두 redis의 부하를 최소화하기 위해 robots.txt 콘텐츠와 같은 중요한 도메인 데이터의 LRU 캐시를 유지 관리했습니다.</li>
</ul>
</li>
<li><strong>Pool of parser processes:</strong>
<strong>파서 프로세스 풀:</strong>
<ul>
<li>Parsers operated similarly to fetchers; each consisted of 80 async workers pulling the next item from the parse queue, parsing the HTML content, extracting links to write back to the appropriate domain frontiers in redis, and writing the saved content to persistent storage. The reason the concurrency was much lower is because parsing is CPU-bound rather than IO-bound (although parsers still needed to talk to redis and occasionally fetch robots.txt), and 80 workers was enough to saturate the CPU.
파서는 페처와 유사하게 작동했습니다. 각각은 구문 분석 대기열에서 다음 항목을 가져오고, HTML 콘텐츠를 구문 분석하고, 링크를 추출하여 Redis의 적절한 도메인 프론티어에 다시 쓰고, 저장된 콘텐츠를 영구 스토리지에 쓰는 80개의 비동기 작업자로 구성되었습니다. 동시성이 훨씬 낮은 이유는 구문 분석이 IO 바운드가 아닌 CPU 바운드이기 때문이며(파서는 여전히 redis와 통신하고 때때로 robots.txt 가져와야 함) 80명의 작업자가 CPU를 포화시키기에 충분했기 때문입니다.</li>
</ul>
</li>
<li><strong>Other: 다른:</strong>
<ul>
<li>For persistent storage, I followed prior art and used instance storage. The textbook interview solution will tell you to use S3; I considered this, but S3 charges per-request as well as pro-rated GB-months, and holding 1 billion pages assuming 250KB per page (250TB total) for just a single day would’ve cost <code>0.022*1000*250*(1/30)+0.005*1e6</code> = $5183.33 with the standard tier or <code>0.11*1000*250*(1/30)+0.00113*1e6</code> = $2046.67 with express - an order of magnitude over what I ended up spending! Even ignoring all PUT costs, it would’ve been $183.33 at standard or $916.67 at express to hold my data for a day, meaning even if I’d batched pages together it wouldn’t have been competitive.
영구 스토리지의 경우 기존 기술을 따르고 인스턴스 스토리지를 사용했습니다. 교과서 인터뷰 솔루션은 S3를 사용하도록 지시합니다. 나는 이것을 고려했지만 S3는 요청당 요금과 비례 배분된 GB-월을 청구하며, 단 하루 동안 페이지당 250KB(총 250TB)를 가정할 때 10억 페이지를 보유하면 비용 <code>0.022*1000*250*(1/30)+0.005*1e6</code> = 표준 계층의 경우 $5183.33 또는 <code>0.11*1000*250*(1/30)+0.00113*1e6</code> 익스프레스의 경우 = $2046.67 - 내가 지출한 금액보다 훨씬 더 비정상적입니다! 모든 PUT 비용을 무시하더라도 표준으로 $183.33 또는 $916.67가 되었을 것입니다 Express에서 하루 동안 내 데이터를 보관했기 때문에 페이지를 함께 일괄 처리하더라도 경쟁력이 없었을 것입니다.</li>
<li>I ended up going with the <code>i7i</code> series of storage-optimized instances, and truncated my saved pages to ensure they fit. Obviously truncating wouldn’t be a good idea for a real crawler; I thought about using a fast compression method in the parser like snappy or a slower, background compressor, but didn’t have time to try.
결국 <code>i7i</code> 시리즈 스토리지에 최적화된 인스턴스를 사용했고 저장된 페이지를 잘라 적합한지 확인했습니다. 분명히 자르는 것은 실제 사람에게 좋은 생각이 아닙니다. 크롤러; 파서에서 snappy 또는 더 느린 백그라운드 압축기와 같은 빠른 압축 방법을 사용하는 것에 대해 생각했지만 시도 할 시간이 없었습니다.</li>
<li>The first fetcher process in the pool was also designated the “leader” and would periodically write metrics to a local prometheus DB. In a real system it would’ve been better to have a single metrics DB for all nodes.
풀의 첫 번째 가져오기 프로세스도 “리더”로 지정되었으며 주기적으로 로컬 프로메테우스 DB에 메트릭을 씁니다. 실제 시스템에서는 모든 노드에 대해 단일 메트릭 DB를 사용하는 것이 더 좋았을 것입니다.</li>
</ul>
</li>
</ul>
<p>The final cluster consisted of:
최종 클러스터는 다음으로 구성되었습니다.</p>
<ul>
<li>12 nodes 12 노드</li>
<li>Each on an <code>i7i.4xlarge</code> machine with 16 vCPUs, 128GB RAM, 10Gbps network bandwidth, and 3750GB instance storage
각각 16개의 vCPU, 128GB RAM, 10Gbps 네트워크 대역폭 및 3750GB 인스턴스 스토리지가 있는 <code>i7i.4xlarge</code> 머신에 있습니다.</li>
<li>Each centered around 1 redis process + 9 fetcher processes + 6 parser processes
각각은 1개의 redis 프로세스 + 9개의 페처 프로세스 + 6개의 파서 프로세스를 중심으로 했습니다</li>
</ul>
<p>The domain seed list was sharded across the nodes in the cluster with no cross-node communication. Since I also only crawled seeded domains, that meant nodes crawled their own non-overlapping regions of the internet. This was mainly because I ran out of time trying to get my alternate design (with cross-communication) working.
도메인 시드 목록은 노드 간 통신 없이 클러스터의 노드 간에 샤딩되었습니다. 또한 시드된 도메인만 크롤링했기 때문에 노드가 인터넷의 겹치지 않는 자체 영역을 크롤링한다는 의미였습니다. 이는 주로 대체 디자인(교차 통신 포함)을 작동시키는 데 시간이 부족했기 때문입니다.</p>
<p>Why just 12 nodes? I found in one experiment that sharding the seed domains too thin led to a serious hot shard problem where some nodes with very popular domains had lots of work to do while others finished quickly. I also stopped the vertical scaling of the fetcher and parser pools at 15 processes total per redis process because redis began to hit 120 ops/sec and I’d read that any more would cause issues (given more time, I would’ve ran experiments to find the exact saturation point).
왜 12개의 노드만 있습니까? 한 실험에서 시드 도메인을 너무 얇게 샤딩하면 매우 인기 있는 도메인을 가진 일부 노드는 해야 할 작업이 많고 다른 노드는 빨리 끝나는 심각한 핫 샤드 문제가 발생한다는 것을 발견했습니다. 또한 redis가 초당 120 ops에 도달하기 시작했고 더 이상 문제가 발생할 수 있다는 것을 읽었기 때문에 redis 프로세스당 총 15 개의 프로세스에서 fetcher 및 parser 풀의 수직 확장을 중지했습니다 (더 많은 시간이 주어지면 정확한 포화 지점을 찾기 위해 실험을 실행했을 것입니다).</p>
<h3 id="alternatives-investigated">Alternatives investigated</h3>
<p>조사된 대안</p>
<p>I went through a few different designs before ending up with the one above. It seems like most recent crawlers[1][2][3] use a fast in-memory datastore like Redis, and for good reason. I made small-scale prototypes with SQLite and PostgreSQL backends, but making frontier queries fast was overly complex despite the conceptual simplicity of the data structure. AI coding tools helped with this exploration a lot; I’ve written about this <a href="https://andrewkchan.dev/posts/systems.html">here</a>.
위의 디자인으로 끝나기 전에 몇 가지 다른 디자인을 거쳤습니다. 가장 최근의 크롤러[1][2][3]는 Redis와 같은 빠른 메모리 내 데이터 저장소를 사용하는 것 같으며 그럴 만한 이유가 있습니다. SQLite 및 PostgreSQL 백엔드로 소규모 프로토타입을 만들었지만 데이터 구조의 개념적 단순성에도 불구하고 프론티어 쿼리를 빠르게 만드는 것은 지나치게 복잡했습니다. AI 코딩 도구는 이러한 탐색에 많은 도움이 되었습니다. 나는 <a href="https://andrewkchan.dev/posts/systems.html">여기에</a> 이것에 대해 썼습니다.</p>
<p>I also tried pretty hard to make vertically scaling a single node work; I was optimistic about this because so many of the hardware bottlenecks that had restricted past big crawls[1][4] to distributed systems seemed to have disappeared. For instance, AWS offers a <code>i7i.48xlarge</code> instance which is essentially just 12 <code>i7i.4xlarge</code> machines stuck together. It has quite a bit less network bandwidth (100Gbps instead of 12x25Gbps), but at the throughput needed to hit 1 billion pages in 24 hours, even if every page was 1MB (which wasn’t the case), I’d only be using <code>8*1e6*(1e9/86400)=92Gbps</code>, with room leftover for outbound (which certainly wasn’t 1MB per request!).
나는 또한 단일 노드를 수직으로 확장하기 위해 꽤 열심히 노력했습니다. 나는 이것에 대해 낙관적이었는데, 과거의 대규모 크롤링[1][4]을 분산 시스템에 제한했던 많은 하드웨어 병목 현상이 사라진 것처럼 보였기 때문입니다. 예를 들어, AWS는 기본적으로 12개에 불과한 <code>i7i.48xlarge</code> 인스턴스를 제공합니다. <code>i7i.4xlarge</code> 머신이 서로 붙어 있습니다. 네트워크 대역폭은 상당히 적지만(12x25Gbps 대신 100Gbps) 24시간 동안 10억 페이지에 도달하는 데 필요한 처리량에서는 모든 페이지가 1MB이더라도(그렇지 않음) <code>8*1e6*(1e9/86400)=92Gbps</code>만 사용하고 아웃바운드를 위한 공간이 남아 있습니다(요청당 1MB는 아니었습니다!).</p>
<p>The first large-scale design I tried packed everything onto a single <code>i7i.48xlarge</code>, organizing processes into “pods” which looked a lot like the nodes in my final cluster (groups of 16 processes with a single redis instance), but with cross-communication allowed. A second design removed the cross-communication and just ran independent pods; a large run with this yielded disappointing results (the entire system managed only 1k pages/sec, which was only a bit over the throughput of a single node in the final cluster). I ran out of my timebox, so gave up and moved to horizontal scaling. I suspect the limiting factor may be more software (operating system resources) rather than hardware.
내가 시도한 첫 번째 대규모 설계는 모든 것을 단일 <code>i7i.48xlarge</code>에 압축하여 프로세스를 최종 클러스터의 노드와 매우 유사한 “포드”로 구성했습니다(16개의 프로세스 그룹). 단일 redis 인스턴스)이지만 교차 통신이 허용됩니다. 두 번째 설계는 교차 통신을 제거하고 독립적인 포드를 실행했습니다. 이를 대규모로 실행하면 실망스러운 결과가 나왔습니다 (전체 시스템은 초당 1k 페이지만 관리했는데, 이는 최종 클러스터에서 단일 노드의 처리량을 약간 초과했습니다.) 타임박스가 다 떨어져서 포기하고 수평 스케일링으로 이동했습니다. 제한 요인이 하드웨어보다는 소프트웨어(운영 체제 리소스)가 더 많을 수 있다고 생각합니다.</p>
<h2 id="learnings-학습">Learnings 학습</h2>
<h3 id="parsing-is-a-big-bottleneck">Parsing is a big bottleneck</h3>
<p>구문 분석은 큰 병목 현상입니다.</p>
<p>I was really surprised by how much of a bottleneck parsing was. In the final system, I only had to allocate processes in a 2:3 parsing-to-fetching ratio, but it didn’t start that way, and it took many iterations to get there. In fact, in the first system I built with dedicated parsing/fetching processes, 2 parsers were needed to keep up with 1 (partially idle) fetcher with 1000 workers running at 55 pages/sec. It really looked like parsing was going to keep me from hitting a billion on budget!
나는 구문 분석이 얼마나 많은 병목 현상을 일으키는지 정말 놀랐습니다. 최종 시스템에서는 구문 분석 대 가져오기 비율이 2:3으로 프로세스를 할당하기만 하면 되었지만 그렇게 시작되지 않았고 거기에 도달하는 데 많은 반복이 필요했습니다. 사실, 전용 구문 분석 / 페치 프로세스로 구축 한 첫 번째 시스템에서는 55 페이지 / 초로 실행되는 1000 명의 작업자와 함께 1 개의 (부분적으로 유휴 상태) 페처를 따라잡기 위해 2 개의 파서가 필요했습니다. 구문 분석이 예산에서 10억 달러를 달성하지 못하게 할 것 같았습니다!</p>
<p>This was really surprising to me because it meant my quad-core node wasn’t achieving the same throughput that a weaker quad-core box could in 2012. Profiles showed that parsing was clearly the bottleneck, but I was using the same <code>lxml</code> parsing library that was popular in 2012 (as suggested by Gemini). I eventually figured out that it was because the average web page has gotten a lot bigger: metrics from a test run indicated the P50 uncompressed page size is now 138KB5, while the mean is even larger at 242KB - many times larger than Nielsen’s estimated average of 51KB in 2012!
이것은 내 쿼드 코어 노드가 2012년에 더 약한 쿼드 코어 박스가 할 수 있는 것과 동일한 처리량을 달성하지 못했다는 것을 의미했기 때문에 정말 놀랐습니다. 프로필은 구문 분석이 분명히 병목 현상임을 보여주었지만 2012년에 인기를 끌었던 것과 동일한 <code>lxml</code> 구문 분석 라이브러리를 사용하고 있었습니다(Gemini가 제안한 대로). 테스트 실행의 지표에 따르면 P50 비압축 페이지 크기는 현재 138KB입니다5, 평균은 242KB로 닐슨의 추정 평균보다 몇 배 더 큰 것으로 나타났습니다. 2012년에는 51KB!</p>
<p>Two things ended up helping the most:
두 가지가 가장 큰 도움이 되었습니다.</p>
<ul>
<li>I switched from <code>lxml</code> to <code>selectolax</code>, a much newer library wrapping Lexbor, a modern parser in C++ designed specifically for HTML5. The page claimed it can be 30 times faster than lxml. It wasn’t 30x overall, but it was a huge boost.
나는 <code>lxml</code>에서 HTML5 용으로 특별히 설계된 C ++의 최신 파서 인 Lexbor를 래핑하는 훨씬 새로운 라이브러리 인 <code>selectolax</code>로 전환했습니다. 페이지는 lxml보다 30배 빠릅니다. 전체적으로 30배는 아니었지만 엄청난 향상이었습니다.</li>
<li>I also truncated page content to 250KB before passing it to the parser. Since the truncation threshold is above the mean and nearly double the median, I think the rationale from Nielsen[1] still holds: we’re capturing most web pages in their entirety, which should be enough for most applications.
또한 파서에 전달하기 전에 페이지 내용을 250KB로 잘랐습니다. 잘림 임계값이 평균보다 높고 중앙값의 거의 두 배에 달하기 때문에 Nielsen[1]의 근거는 여전히 유효하다고 생각합니다: 우리는 대부분의 웹 페이지 전체를 캡처하고 있으며 이는 대부분의 애플리케이션에 충분할 것입니다.</li>
</ul>
<p>With this setup, I was able to achieve ~160 pages parsed per second with a single parser process, which allowed my final setup to use 9x fetchers and 6x parsers to crawl ~950 pages/sec.
이 설정을 통해 단일 파서 프로세스로 초당 ~160페이지를 구문 분석할 수 있었으며, 이를 통해 최종 설정에서 9x 페처와 6x 파서를 사용하여 ~950페이지/초를 크롤링할 수 있었습니다.</p>
<h3 id="fetching-both-easier-and-harder">Fetching: both easier and harder</h3>
<p>가져오기: 더 쉽고 더 어렵습니다.</p>
<p>Many treatments of crawling take network bandwidth and DNS to be important bottlenecks. For instance, while researching this topic I emailed <a href="https://www.cs.cmu.edu/~callan/">Jamie Callan</a> from CMU about the Sapphire project from 2009[4]; Professor Callan told me that DNS resolution throughput was a bottleneck, and for a later crawl in 2012 which used the CMU campus network, the crawl throughput had to be throttled to avoid using all of the bandwidth. This <a href="https://www.hellointerview.com/learn/system-design/problem-breakdowns/web-crawler">interview analysis from Evan King</a> from about a year ago also suggests optimizations for DNS resolution.
크롤링에 대한 많은 처리는 네트워크 대역폭과 DNS를 중요한 병목 현상으로 간주합니다. 예를 들어, 이 주제를 연구하는 동안 CMU의 <a href="https://www.cs.cmu.edu/~callan/">Jamie Callan에게</a> 2009년 사파이어 프로젝트에 대해 이메일을 보냈습니다[4]; Callan 교수는 DNS 확인 처리량이 병목 현상이며 CMU 캠퍼스 네트워크를 사용한 2012년 이후 크롤링의 경우 모든 대역폭을 사용하지 않도록 크롤링 처리량을 제한해야 한다고 말했습니다. 에<a href="https://www.hellointerview.com/learn/system-design/problem-breakdowns/web-crawler">반 킹의 인터뷰 분석</a> 약 1년 전부터 DNS 확인에 대한 최적화도 제안합니다.</p>
<p>For my crawl, DNS didn’t come up at all. I think this is because I limited crawling to my seed list of the top ~1 million domains. Network bandwidth also wasn’t near saturated for any of the nodes in the cluster; most nodes averaged around 1 GB/s (8 Gbps) at steady state, but the max bandwidth for <code>i7i.4xlarge</code> is 25 Gbps. Datacenter bandwidth is abundant these days, especially for AI: AWS offers a <a href="https://aws.amazon.com/ec2/instance-types/p6/">P6e-GB200</a> instance with 28.8 <em>terabits</em> of network bandwidth!
내 크롤링에서는 DNS가 전혀 나타나지 않았습니다. 크롤링을 상위 ~100만 개 도메인의 시드 목록으로 제한했기 때문이라고 생각합니다. 또한 네트워크 대역폭은 클러스터의 노드에 대해 거의 포화 상태가 아니었습니다. 대부분의 노드는 정상 상태에서 평균 약 1GB/s(8Gbps)였지만 <code>i7i.4xlarge</code>의 최대 대역폭은 25Gbps입니다. 요즘 데이터 센터 대역폭은 특히 AI의 경우 풍부합니다: AWS는 28.8_테라비트_의 네트워크 대역폭을 갖춘 <a href="https://aws.amazon.com/ec2/instance-types/p6/">P6e-GB200</a> 인스턴스를 제공합니다!</p>
<p>That said, one part of fetching got harder: a LOT more websites use SSL now than a decade ago. This was crystal clear in profiles, with SSL handshake computation showing up as the most expensive function call, taking up a whopping 25% of all CPU time on average, which - given that we weren’t near saturating the network pipes, meant fetching became bottlenecked by the CPU before the network!
즉, 가져오기의 한 부분은 10 년 전보다 훨씬 더 많은 웹 사이트가 SSL을 사용한다는 것입니다. 이는 SSL 핸드셰이크 계산이 가장 비용이 많이 드는 함수 호출로 표시되어 평균적으로 모든 CPU 시간의 무려 25%를 차지하는 프로필에서 매우 분명했으며, 이는 네트워크 파이프가 거의 포화되지 않았다는 점을 감안할 때 가져오기가 네트워크 이전에 CPU에 의해 병목 현상이 발생한다는 것을 의미했습니다!</p>
<p><img src="https://andrewkchan.dev/posts/crawler-assets/ssl.png" alt=""></p>
<p><em>From <a href="https://letsencrypt.org/stats/">https://letsencrypt.org/stats/</a> - SSL loads in Firefox have gone from 30% in 2014 to >80% in 2025.</em>
<a href="https://letsencrypt.org/stats/">*https://letsencrypt.org/stats/</a> 년부터 - Firefox의 SSL 로드는 2014년 30%에서 2025년 >80%로 증가했습니다.*</p>
<h3 id="the-big-crawl-큰-크롤링">The big crawl 큰 크롤링</h3>
<p><img src="https://andrewkchan.dev/posts/crawler-assets/shard6-metrics1.png" alt=""></p>
<p><img src="https://andrewkchan.dev/posts/crawler-assets/shard6-metrics2.png" alt=""></p>
<p><em>Metrics for one of the nodes early on in the crawl. Some of the units in the grafana dashboard are wrong (e.g. error rate and parse queue size are using “bytes” by mistake)</em>
<em>크롤링 초기에 노드 중 하나에 대한 메트릭입니다. grafana 대시보드의 일부 단위가 잘못되었습니다(예: 오류율 및 구문 분석 대기열 크기가 실수로 “바이트”를 사용하고 있음).</em></p>
<p>Before running the big crawl with 12 <code>i7i.4xlarge</code> nodes, the biggest experiment I’d done had been a several-hour run on a single <code>i7i.2xlarge</code>, so there were quite a few surprises from the leap in scale that emerged over the course of the run, and I spent an entire Sunday from sunrise to sunset (and beyond) being oncall for my own run, watching metrics and hopping into to fix issues. Some of these were stupid operational oversights like forgetting to set up log rotation and then running out of space on the root volume, but the biggest issue was memory growth due to the frontiers.
12개의 <code>i7i.4xlarge</code> 노드로 빅 크롤링을 실행하기 전에 제가 한 가장 큰 실험은 단일 <code>i7i.2xlarge</code>에서 몇 시간 동안 실행한 것이었기 때문에 달리기 과정에서 나타난 규모의 도약, 그리고 일출부터 일몰까지(그리고 그 이후) 일요일 내내 내 달리기를 위해 대기하고, 지표를 보고, 수정하기 위해 뛰어들었습니다 문제. 이들 중 일부는 로그 순환을 설정하는 것을 잊어버린 다음 루트 볼륨의 공간이 부족한 것과 같은 어리석은 운영 실수였지만 가장 큰 문제는 메모리 증가였습니다. 국경으로.</p>
<p>This was specific to my design, which placed all frontier data in-memory. I’d had memory issues on the earlier, smaller-scale crawls too, but on other components such as the HTTP client or the visited entries. I’d calculated out the memory headroom needed for 1 billion visited pages across those components, but failed to anticipate that the frontiers of certain very hot domains would grow to become tens of gigabytes (hundreds of millions or billions of URLs), and halfway through the run, my nodes started dropping like flies. I had to manually intervene by restarting machines which had become unresponsive and truncating frontiers. Luckily the fault tolerance made resumption after fixing easy.
이것은 모든 프론티어 데이터를 메모리에 배치하는 내 설계에만 해당되었습니다. 이전의 소규모 크롤링에서도 메모리 문제가 있었지만 HTTP 클라이언트 또는 방문한 항목과 같은 다른 구성 요소에서도 메모리 문제가 발생했습니다. 이러한 구성 요소에서 10억 개의 방문 페이지에 필요한 메모리 여유 공간을 계산했지만 특정 매우 인기 있는 도메인의 프론티어가 수십 기가바이트(수억 또는 수십억 개의 URL)로 성장할 것이라는 것을 예상하지 못했고 실행 중간에 내 노드가 파리처럼 떨어지기 시작했습니다. 응답하지 않는 기계를 다시 시작하고 프론티어를 잘라 수동으로 개입해야 했습니다. 운 좋게도 내결함성 덕분에 수정 후 재개가 쉬워졌습니다.</p>
<p>Were the problematic domains tarpits? From what I could tell, most were just really popular websites with lots of links. For example, <code>yahoo.com</code> and <code>wikipedia.org</code> were among them. Another was a “cosplayfu” website which looked like a strange shopping site on first glance, but after searching on the internet seemed legit. In any case, the most problematic domains were simply added to my manual exclusion list.
문제가 있는 도메인이 방침이었습니까? 내가 알 수 있는 바로는 대부분 링크가 많은 정말 인기 있는 웹사이트였습니다. 예를 들어 <code>yahoo.com</code> 및 <code>wikipedia.org</code> 그들 중 하나였습니다. 또 다른 하나는 언뜻 보기에는 이상한 쇼핑 사이트처럼 보였지만 인터넷에서 검색해 보면 합법적인 것처럼 보였던 “코스프레푸” 웹사이트였습니다. 어쨌든 가장 문제가 되는 도메인은 단순히 수동 제외 목록에 추가되었습니다.</p>
<h2 id="discussion-토론">Discussion 토론</h2>
<h3 id="theory-vs-practice-이론-대-실습">Theory vs. Practice 이론 대 실습</h3>
<p>How does my crawler contrast against textbook solutions like the one in Evan King’s <a href="https://www.hellointerview.com/learn/system-design/problem-breakdowns/web-crawler">HelloInterview analysis</a>? The metric of interest here is probably King’s “hand-wavy” estimate that 5 machines can crawl 10 billion pages in 5 days. In this claim, the machines are completely dedicated to fetching, with the parsers and frontier datastore living elsewhere. There are no details on the hardware of each machine besides assuming a 400Gbps bandwidth per-machine from which we achieve 30% utilization.
내 크롤러는 Evan King의 <a href="https://www.hellointerview.com/learn/system-design/problem-breakdowns/web-crawler">HelloInterview 분석</a>과 같은 교과서 솔루션과 어떻게 대조됩니까? 여기서 관심 있는 지표는 아마도 5대의 기계가 5일 동안 100억 페이지를 크롤링할 수 있다는 King의 “손 모양” 추정일 것입니다. 이 주장에서 기계는 가져오기에 전적으로 전념하고 있습니다. 다른 곳에 있는 파서와 프론티어 데이터 저장소. 30%의 활용도를 달성하는 기계당 400Gbps 대역폭을 가정하는 것 외에는 각 기계의 하드웨어에 대한 세부 정보가 없습니다.</p>
<p>The utilization at least is about right; my nodes offered only 25Gbps, but I indeed got about 32% utilization with 8Gbps in + out at steady state. That said, I only dedicated 9/16 cores on each machine to fetching, which using naive scaling suggests I could’ve achieved 53% network utilization. Similarly, since I used 12 machines to crawl 1 billion pages in ~1 day, I likely could have achieved the same 1 billion per day throughput with 6.75 fetcher-only machines. If we assume straightforward scaling from <code>i7i.4xlarge</code> to <code>i7i.8xlarge</code> as well, this implies 6.75 double-size fetcher-only machines could crawl 10 billion pages in 5 days. So King’s number is not too far off, but might require a bit more optimization than I did with my system!
활용도는 적어도 적당합니다. 내 노드는 25Gbps만 제공했지만 실제로 정상 상태에서 8Gbps 입력 + 출력으로 약 32%의 활용도를 얻었습니다. 즉, 각 시스템에서 9/16 코어만 가져오기 전용으로 사용했는데, 순진한 스케일링을 사용하면 53%의 네트워크 사용률을 달성할 수 있었습니다. 마찬가지로 12대의 컴퓨터를 사용하여 ~1일 동안 10억 페이지를 크롤링했기 때문에 6.75개의 페처 전용 컴퓨터로 동일한 하루 10억 처리량을 달성할 수 있었을 것입니다. <code>i7i.4xlarge</code>에서 <code>i7i.8xlarge</code>로 간단하게 확장한다고 가정하면 이는 6.75 더블 사이즈를 의미합니다. Fetcher 전용 머신은 5일 만에 100억 페이지를 크롤링할 수 있습니다. 따라서 King의 숫자는 그리 멀지 않지만 내 시스템보다 조금 더 최적화가 필요할 수 있습니다!</p>
<h3 id="what-now-이번엔-또-뭐예요">What now? 이번엔 또 뭐예요?</h3>
<p>To be honest I’m surprised so much of the web is still accessible6 without running JS. It’s great! I found out about some cool websites like <a href="http://ancientfaces.com/">ancientfaces.com</a> through this crawl. But I noticed that even for many crawl-able websites like GitHub, the downloaded pages didn’t really have meaningfully marked-up text content; it was all embedded in gigantic strings which presumably were to be rendered client-side by what we might consider “lightweight” JS scripts. I think interesting future work would involve addressing this elephant: how does large-scale crawling look like when we actually need to render pages dynamically? I suspect the same scale will be much more expensive.
솔직히 말해서 JS를 실행하지 않고도웹의 많은 부분에 여전히 액세스할 수 있다는 사실에 놀랐습니다. 대단해요! 나는 <a href="http://ancientfaces.com/">ancientfaces.com</a> 같은 멋진 웹사이트에 대해 알게 되었습니다. 이 크롤링. 그러나 GitHub와 같은 크롤링 가능한 많은 웹 사이트의 경우에도 다운로드한 페이지에는 실제로 의미 있게 표시된 텍스트 콘텐츠가 없다는 것을 알았습니다. 그것은 모두 거대하게 내장되어 있었습니다. 문자열은 아마도 우리가 “경량” JS 스크립트로 간주할 수 있는 것에 의해 클라이언트 측에서 렌더링될 것입니다. 흥미로운 미래 작업에는 이 코끼리를 다루는 것이 포함될 것이라고 생각합니다. 실제로 페이지를 동적으로 렌더링해야 할 때 대규모 크롤링은 어떻게 보일까요? 같은 규모가 훨씬 더 비쌀 것 같아요.</p>
<p>Another question is: what do the shape and distribution of the billion pages I crawled look like? I kept a sample but haven’t gotten the time to run any analytics. It will be interesting to know some basic facts about metadata, such as how many crawled URLs were actually alive vs. dead, how many were of an HTML content type vs. multimedia, etc.
또 다른 질문은 내가 크롤링한 10억 페이지의 모양과 분포는 어떻게 생겼는가 하는 것입니다. 샘플을 보관했지만 분석을 실행할 시간이 없습니다. 실제로 살아 있는 URL과 죽은 URL의 수, HTML 콘텐츠 유형 및 멀티미디어 등 메타데이터에 대한 몇 가지 기본 사실을 아는 것은 흥미로울 것입니다.</p>
<p>Finally, this post covered some of the larger ways that the web has changed over the last decade, but the landscape is shifting yet again. Aggressive crawling/scraping backed by massive resources isn’t new (Facebook previously ran into hot water for <a href="https://news.ycombinator.com/item?id=23490367">OpenGraph scraping</a>), but has been intensified with AI. I took politeness very seriously, following conventions like robots.txt and more, but many crawlers don’t and the internet is starting to develop defenses. Cloudflare’s experimental <a href="https://blog.cloudflare.com/introducing-pay-per-crawl/">pay-per-crawl</a> feature is a new offering from the market that could help a lot.
마지막으로, 이 게시물에서는 지난 10년 동안 웹이 변화했지만 환경이 다시 변화하고 있는 더 큰 방법 중 일부를 다루었습니다. 방대한 리소스로 뒷받침되는 공격적인 크롤링/스크래핑은 새로운 것이 아니지만(Facebook은 이전에 <a href="https://news.ycombinator.com/item?id=23490367">OpenGraph 스크래핑</a>으로 인해 뜨거운 물에 빠졌습니다) AI로 인해 더욱 강화되었습니다. 나는 매우 공손하게 받아들였습니다 진지하게, robots.txt 등과 같은 규칙을 따르지만 많은 크롤러는 그렇지 않으며 인터넷은 방어 체계를 개발하기 시작했습니다. Cloudflare의 실험적 <a href="https://blog.cloudflare.com/introducing-pay-per-crawl/">크롤링당 지불</a> 기능은 많은 도움이 될 수 있는 시장의 새로운 제품입니다.</p> </article> </div> <script type="module">
      // 목적: index.json에서 현재 글 메타/썸네일을 찾아 상세 화면에 반영한다.
      async function hydrateMeta() {
        try {
          const BASE = import.meta.env.BASE_URL;
          const slug = decodeURIComponent(location.pathname.replace(/.*\/post\//,'').replace(/\/?$/,''));
          const res = await fetch(`${BASE}index.json`);
          const data = await res.json();
          const items = (data && data.items) || [];
          const item = items.find((i) => i.slug === slug);
          if (!item) return;

          const hero = document.getElementById('hero');
          const heroImg = document.getElementById('heroImg');
          const source = document.getElementById('source');
          const cta = document.getElementById('ctaSource');
          if (item.thumbnail && hero && heroImg) {
            heroImg.setAttribute('src', item.thumbnail);
            hero.style.display = 'block';
          }
          if (item.source_url && source && cta) {
            source.setAttribute('href', item.source_url);
            cta.setAttribute('href', item.source_url);
            source.style.display='inline-block';
            cta.style.display='inline-block';
          }
        } catch {}
      }
      hydrateMeta();

      // 복사 버튼 제거됨 — 상단에 원문 보기 버튼만 유지
    </script> </body> </html>