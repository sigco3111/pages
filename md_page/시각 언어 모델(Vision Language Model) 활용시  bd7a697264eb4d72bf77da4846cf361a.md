# 시각 언어 모델(Vision Language Model) 활용시 꼭 알아야 할 사실

발견일: 2025/07/08
원문 URL: https://devocean.sk.com/blog/techBoardDetail.do?ID=167591
분류: 인사이트
원문 Source: 🔗devocean.sk
즐겨찾기: No

![](https://devocean.sk.com/thumnail/2025/7/8/0f8747af1ebbec0805f3444775c98e4715b051d7c2bcad90468caee53f829a31.png)

안녕하세요.

SK하이닉스에서 OCR 관련 프로젝트를 진행하고 있는 담당자 입니다.

최근에는 거의 모든 생성형 AI 도구들이 멀티 모달을 지원하고 있고, 또 일상 생활에서 자연스럽게 활용하고 있습니다.

(모르는 언어로 된 메뉴판을 번역한다던가, 어떤 사진인지 맞추게 시킨다던가)

활용해보면 굉장히 인식률이 좋고, 자연스럽게 기존 OCR 업무에도 확장해서 사용하는 시도가 많이 보입니다.

실제로 현업에서도 VLM (Vision Language Model)을 활용해서 PPT 내용을 읽어오거나, 반도체 Pattern의 결함을 찾는 시도들을 많이 하고 있습니다.

실제로 OCR 관련 과제를 할때도 OCR 모델과 생성형 AI 모델을 결합해서 프로젝트를 진행하고 있습니다.

그런데, 사실 VLM이 장님이자, 실제 사진을 제대로 보는게 아니라는 충격적인(?) 논문을 보게되어 공유 드리고자 글을 쓰게 되었습니다.

VLM을 활용해서 이미지 인식 과제를 진행하시는 분들께서는 꼭 참고해보시면 도움이 될거라고 생각 됩니다.

## 1. 사실 VLM은 장님이다?

여기 매우 쉬운 문제가 있습니다. 빨간선과 파란선이 교점을 몇개 가지고 있는지 맞추는 문제인데요.

Claude의 최신 모델인 Sonnet-4로 물어봤습니다.

[](https://devocean.sk.com/editorImg/2025/6/29/d9618efb5ddc7588d908efc543403c25637c88241e18fe96f4ef379604be6d36)

정답은 0개로 사실 누구나 맞출 수 있는 문제 인데, VLM은 마치 장님 처럼 틀립니다.

위 예시 처럼 논문에서는 유치원생 수준이라면 누구나 맞출 수 있는 "공간 관계" 문제를 주고, VLM 모델들이 얼마나 정답을 잘 맞추는지 테스트 해본 내용이 소개되고 있습니다.

총 7개의 Task가 있고, 모두 사람이라면 손쉽게 맞출 수 있는 문제로 구성되어 있습니다.

[](https://devocean.sk.com/editorImg/2025/6/29/1455438efdd496b74b85545638519b51cbaa42f10dc2e46cba3090701bd474ec)

1. 교점의 개수 맞추기
2. 2개의 원이 오버랩 되어있는지 판단하기
3. 글자에 빨간색 동그라미를 치고, 동그라미친 단어 맞추기
4. 원이 몇개 있는지 맞추기
5. 사각형이 몇개 있는지 맞추기
6. 표의 행/열 개수 맞추기
7. 노선도로 갈 수 있는 개수 맞추기

전부 쉬운 난이도의 문제지만 아래 벤치마크 결과를 보면 각 Task별 정확도는 상용으로는 전혀 쓰지 못할 수준임을 알 수 있습니다.

[](https://devocean.sk.com/editorImg/2025/6/29/d137b8158ac4a8a5de4c856ce69f42ffb7bd61bbf25175593adc504d7a8979d9)

출처 : [Vision language models are blind](https://vlmsareblind.github.io/)

## 2. VLM은 통념을 벗어나지 못한다?

이 내용도 충격적인데요. 우리가 흔히 통념으로 알고 있는 내용 (개의 다리는 4개, 아디다스 로고는 줄 3개 등)

에서 조금만 (개의 다리를 5개도 바꾼다던가) 내용을 바꾸면 VLM은 틀린 답을 내놓습니다.

[](https://devocean.sk.com/editorImg/2025/6/29/68a0aa22379265c52aa0bd9e93e6f513dd610ebb4c74968eccd6661926fb95f3)

퓨마 그림에 다리 1개만 추가 했을 뿐인데, 우리가 아는 최신 모델이 전부 틀리는걸 확인할 수 있습니다.

아디다스 로고에 줄 1개만 추가해도 통념을 벗어나지 못하고 3개로 답변 하네요.

실제 논문에서는 위와 같이 우리가 알고 있고, LLM도 알고 있는 통념에 살짝만 변주를 주어도 이미지 분석을 수행 못하게 됩니다.

> VLM모델은 실제 시각 분석 결과보다 학습된 기억에 더 의존하고 있음을 알 수 있습니다.
> 

아래 이미지는 기존 통념에 반하는 내용을 넣고, 각 모델별 질문과 정답을 맞췄는지를 보여줍니다.

(맞추는게 거의 없습니다..)

[](https://devocean.sk.com/editorImg/2025/6/29/b90caac38b017606bc779fa4db03f3cd949619788347b866a73ee7ad401ea38f)

출처 : [Vision Language Models are Biased](https://vlmsarebiased.github.io/)

## 3. 결론

우리가 VLM을 활용하면서 지금까지 생기는 오류들을 기존에는 1) 랜덤 에러 2) 모델 성능 3) 낮은 화질 등으로 생각했지만 실제 VLM은 명확한 구멍이 있으며,

실제 현업에 적용하기 전에 위험성(?)에 대해 고민해봐야 할 것 같습니다.

특히 반도체 Pattern 같은 자연적인 이미지가 아닌 도형의 공간 정보를 해석함에 취약점을 가지고 있고, 아주 조금의 변경으로도 결과가 완전히 뒤바뀔 수 있습니다.

간단하게 VLM의 한계에 관련한 2편의 논문을 살펴보았는데요. 혹시 이미지 인식 관련 과제에 VLM을 활용하시려는 분들께서는 참고가 많이 될 것 같습니다.