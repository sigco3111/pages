# 레퍼런스 기반 애니메이션 채색, LongAnimation

발견일: 2025/07/07
원문 URL: https://github.com/CN-makers/LongAnimation
분류: 오픈소스
원문 Source: 🔗github
즐겨찾기: No

[](https://opengraph.githubassets.com/86cfe0b61cbdf16e0bba9a8f0fe420241a3e3ee6a657e5e2d3978b5e0108e81e/CN-makers/LongAnimation)

# LongAnimation: Long Animation Generation with Dynamic Global-Local Memory
LongAnimation: 동적 전역-로컬 메모리를 사용한 긴 애니메이션 생성

  

[](https://camo.githubusercontent.com/127d20f716b7227446bc8af440e5a6b695d1f6e87e4c1dd3c33098969a2306ca/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d50726f6a656374266d6573736167653d5765627369746526636f6c6f723d626c7565)

[](https://camo.githubusercontent.com/4721e7c059058929d64409fc70e8c46871098ff44e8d0a4e147c7c5e082cbc81/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d323035372e30313934352d6233316231622e737667)

[](https://camo.githubusercontent.com/41acc901d5ed8336e63cb54e3895314b14b3c136badab81b8a09d580d32e3b09/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170616368652d79656c6c6f77)

video.mp4

> [**LongAnimation: Long Animation Generation with Dynamic Global-Local Memory**](https://cn-makers.github.io/long_animation_web/)
[**LongAnimation: 동적 전역-로컬 메모리를 사용한 긴 애니메이션 생성**](https://cn-makers.github.io/long_animation_web/)
> 

[Nan Chen](https://openreview.net/profile?id=~Nan_Chen13)1, [Mengqi Huang](https://corleone-huang.github.io/)1, [Yihao Meng](https://yihao-meng.github.io/)2, [Zhendong Mao](https://faculty.ustc.edu.cn/maozhendong/en/index.htm)†,1
[난 첸](https://openreview.net/profile?id=~Nan_Chen13)1, [멩치 황](https://corleone-huang.github.io/)1, [이하오 멩](https://yihao-meng.github.io/)2, [젠동 마오](https://faculty.ustc.edu.cn/maozhendong/en/index.htm)†,1
1USTC 2HKUST †corresponding author
1 USTC 2HKUST †교신저자

> Existing studies are limited to short-term colorization by fusing overlapping features to achieve smooth transitions, which fails to maintain long-term color consistency. In this study, we propose a dynamic global-local paradigm to achieve ideal long-term color consistency by dynamically extracting global color-consistent features relevant to the current generation.
기존 연구는 부드러운 전환을 달성하기 위해 겹치는 특징을 융합하여 단기적인 색상화에 국한되어 장기적인 색상 일관성을 유지하지 못합니다. 본 연구에서는 현재 세대와 관련된 글로벌 색상 일관성 특징을 동적으로 추출하여 이상적인 장기 색상 일관성을 달성하기 위한 동적 글로벌-로컬 패러다임을 제안합니다.
> 

🎉🎉 Our paper, “LongAnimation: Long Animation Generation with Dynamic Global-Local Memory” accepted by ICCV 2025! Looking forward to seeing you at ICCV then! **Strongly recommend seeing our [demo page](https://cn-makers.github.io/long_animation_web/).**
🎉🎉 우리의 논문 "LongAnimation: Long Animation Generation with Dynamic Global-Local Memory"가 ICCV 2025에 승인되었습니다! 그때 ICCV에서 뵙기를 기대합니다! [**데모 페이지를](https://cn-makers.github.io/long_animation_web/) 참조하는 것이 좋습니다.**

## Showcase 쇼케이스

showcase_1.mp4 showcase_2.mp4 showcase_3.mp4

## Creative usage 창의적인 사용

### Text-guided Background Generation

텍스트 안내 배경 생성

text_1.mp4 text_2.mp4 text_3.mp4

*A boy and a girl in different environment.*
*다른 환경에 있는 소년과 소녀.*

## TODO List ALL 목록

- Release the paper and demo page. Visit [https://cn-makers.github.io/long_animation_web/](https://cn-makers.github.io/long_animation_web/)
논문 및 데모 페이지를 공개합니다. [방문 https://cn-makers.github.io/long_animation_web/](https://cn-makers.github.io/long_animation_web/)
- Release the code.
코드를 해제합니다.

## Requirements 요구 사항

The training is conducted on 6 A100 GPUs (80GB VRAM), the inference is tested on 1 A100 GPU.
훈련은 6개의 A100 GPU(80GB VRAM)에서 수행되며 추론은 1개의 A100 GPU에서 테스트됩니다.

## Setup 설치

```
git clone https://github.com/CN-makers/LongAnimation
cd LongAnimation
```

## Environment 환경

All the tests are conducted in Linux. We suggest running our code in Linux. To set up our environment in Linux, please run:
모든 테스트는 Linux에서 수행됩니다. Linux에서 코드를 실행하는 것이 좋습니다. Linux에서 환경을 설정하려면 다음을 실행하십시오.

```
conda create -n LongAnimation python=3.10 -y
conda activate LongAnimation
bash install.sh
```

## Checkpoints 검사점

1. please download the pre-trained CogVideoX-1.5 I2V checkpoints from [here](https://huggingface.co/THUDM/CogVideoX1.5-5B-I2V), and put the whole folder under `pretrained_weight`, it should look like `./pretrained_weights/CogVideoX1.5-5B-I2V`
[여기에서](https://huggingface.co/THUDM/CogVideoX1.5-5B-I2V) 사전 훈련된 CogVideoX-1.5 I2V 체크포인트를 다운로드하고 전체 폴더를 `pretrained_weight` 아래에 넣으면 다음과 같습니다. `./pretrained_weights/CogVideoX1.5-5B-I2V`
2. please download the pre-trained long video understanding model Video-XL checkpoints from [here](https://huggingface.co/sy1998/Video_XL/tree/main), and put the whole folder under `pretrained_weight`, it should look like `./pretrained_weights/videoxl`
[여기에서](https://huggingface.co/sy1998/Video_XL/tree/main) 사전 훈련된 긴 비디오 이해 모델 Video-XL 체크포인트를 다운로드하고 전체 폴더를 `pretrained_weight` 아래에 놓으면 `./pretrained_weights/videoXL과` 같이 표시되어야 합니다.
3. please download the checkpoint for our SketchDiT and DGLM model from [here](https://huggingface.co/CNcreator0331/LongAnimation/tree/main), and put the whole folder as `./pretrained_weights/longanimation`.
여기에서 SketchDiT 및 DGLM 모델에 대한 체크포인트를 다운로드하고 전체 폴더를 `./pretrained_weights/longanimation` .

## Generate Your Animation! 애니메이션을 생성하세요!

To colorize the target lineart sequence with a specific character design, you can run the following command:
특정 캐릭터 디자인으로 대상 선화 시퀀스를 색칠하려면 다음 명령을 실행할 수 있습니다.

```
bash  long_animation_inference.sh
```

We provide some test cases in `test_json` folder. You can also try our model with your own data. You can change the lineart sequence and corresponding character design in the script `Long_animation_inference.sh`.
폴더에 몇 가지 테스트 사례`test_json` 제공합니다. 자신의 데이터로 모델을 사용해 볼 수도 있습니다. 스크립트 `Long_animation_inference.sh`에서 선화 순서와 해당 캐릭터 디자인을 변경할 수 있습니다.

During the official training, the --height and --weight we used were 576 and 1024 respectively. Additionally, the model can also be compatible with resolutions of 768 in length and 1360 in width respectively.
공식 훈련 기간 동안 우리가 사용한 --height 및 --weight는 각각 576과 1024였습니다. 또한 이 모델은 각각 길이 768, 너비 1360의 해상도와도 호환될 수 있습니다.

## Citation:

Don't forget to cite this source if it proves useful in your research!

```
@misc{chen2025longanimationlonganimationgeneration,
      title={LongAnimation: Long Animation Generation with Dynamic Global-Local Memory}, 
      author={Nan Chen and Mengqi Huang and Yihao Meng and Zhendong Mao},
      year={2025},
      eprint={2507.01945},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.01945}, 
}
```

## Star History

[](https://camo.githubusercontent.com/f6a2989efdd2c8720f169f8390ae37a6b3ca24045d4dd136f55cdebd3e8a0d6c/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d434e2d6d616b6572732f4c6f6e67416e696d6174696f6e26747970653d44617465)